{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import abspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_network import generate_network\n",
    "from utils.prepare_data import prepare_data\n",
    "from utils.popphy_io import save_params, load_params\n",
    "from utils.popphy_io import get_stat, get_stat_dict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from models.PopPhy import PopPhyCNN\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "#from models.PopPhy2 import ResNet\n",
    "from models.PopPhy2 import ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Reading Configuration\n",
    "Configuring which data to read in, minimun threshold needed in an OTU (individual sample must have at least set threshold relative abundance), and how many k folds for k fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'SKG-abx'\n",
    "threshold = 0\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features\n",
    "Reduce amount of OTU features by filtering out OTUs that contain no individual sample with a relative abundance greater than the set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Bacteroidaceae|g__Bacteroides|s__Bacteroides_acidifaciens</th>\n",
       "      <td>35</td>\n",
       "      <td>712</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>609</td>\n",
       "      <td>1129</td>\n",
       "      <td>397</td>\n",
       "      <td>209</td>\n",
       "      <td>1490</td>\n",
       "      <td>...</td>\n",
       "      <td>2941</td>\n",
       "      <td>1171</td>\n",
       "      <td>1891</td>\n",
       "      <td>716</td>\n",
       "      <td>588</td>\n",
       "      <td>26567</td>\n",
       "      <td>18283</td>\n",
       "      <td>2126</td>\n",
       "      <td>554</td>\n",
       "      <td>20731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9049</td>\n",
       "      <td>11919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_murinus</th>\n",
       "      <td>294</td>\n",
       "      <td>258</td>\n",
       "      <td>318</td>\n",
       "      <td>258</td>\n",
       "      <td>403</td>\n",
       "      <td>446</td>\n",
       "      <td>914</td>\n",
       "      <td>761</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>920</td>\n",
       "      <td>721</td>\n",
       "      <td>437</td>\n",
       "      <td>509</td>\n",
       "      <td>6097</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1543</td>\n",
       "      <td>1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_johnsonii</th>\n",
       "      <td>15</td>\n",
       "      <td>135</td>\n",
       "      <td>92</td>\n",
       "      <td>470</td>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>1161</td>\n",
       "      <td>2464</td>\n",
       "      <td>50</td>\n",
       "      <td>1215</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Rikenellaceae|g__Alistipes|s__Alistipes_unclassified</th>\n",
       "      <td>46</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>373</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>242</td>\n",
       "      <td>185</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Bacteroidaceae|g__Bacteroides|s__Bacteroides_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridia UCG-014|f__unclassified|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridia vadinBB60 group|f__unclassified|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Desulfobacterota|c__Desulfovibrionia|o__Desulfovibrionales|f__Desulfovibrionaceae|g__Desulfovibrio|s__Desulfovibrio_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Klebsiella|s__Klebsiella_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    1    2    3    4    5    \\\n",
       "0                                                                             \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   35  712  107    0  616   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0    0    9    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  294  258  318  258  403   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   15  135   92  470  125   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   46  106   12  373   52   \n",
       "...                                                 ...  ...  ...  ...  ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...    0    0    0    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...    0    0    0    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...    0    0    0    0    0   \n",
       "k__Bacteria|p__Desulfobacterota|c__Desulfovibri...    0    0    0    0    0   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0    0    0    0    0   \n",
       "\n",
       "                                                    6     7    8    9     10   \\\n",
       "0                                                                               \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  609  1129  397  209  1490   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  446   914  761    6    78   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   54    30   26   52   151   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   73    98    0   13    40   \n",
       "...                                                 ...   ...  ...  ...   ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...    0     0    0    0     0   \n",
       "k__Bacteria|p__Desulfobacterota|c__Desulfovibri...    0     0    0    0     0   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0     0    0    0     0   \n",
       "\n",
       "                                                    ...   118   119   120  \\\n",
       "0                                                   ...                     \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  ...  2941  1171  1891   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  ...     4     2     0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  ...   920   721   437   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  ...  1161  2464    50   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  ...    92    28   242   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  ...     0     0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  ...     0     0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  ...     6     0     0   \n",
       "k__Bacteria|p__Desulfobacterota|c__Desulfovibri...  ...     0     0     0   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  ...     0     0     0   \n",
       "\n",
       "                                                     121   122    123    124  \\\n",
       "0                                                                              \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   716   588  26567  18283   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0     0   9049  11919   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   509  6097      2      0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  1215   983      0      0   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   185    91      0      0   \n",
       "...                                                  ...   ...    ...    ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...     0     0      0      0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...     0     0      0      0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...     0     0      0      0   \n",
       "k__Bacteria|p__Desulfobacterota|c__Desulfovibri...    12     0      0      0   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0     0      0      0   \n",
       "\n",
       "                                                     125   126    127  \n",
       "0                                                                      \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  2126   554  20731  \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0     0  11064  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  1543  1333      0  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...    73   321      0  \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   277   997      0  \n",
       "...                                                  ...   ...    ...  \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...     0     0      0  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...     0     0      0  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...     0     0      0  \n",
       "k__Bacteria|p__Desulfobacterota|c__Desulfovibri...     0     0      0  \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0     0     12  \n",
       "\n",
       "[692 rows x 127 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/\" + dataset\n",
    "data = pd.read_csv(path + '/abundance.tsv', index_col=0, sep='\\t', header=None)\n",
    "to_drop = data.loc[(data < threshold).all(axis=1)]\n",
    "data = data.drop(to_drop.index)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2d Matrix Representing OTU Data\n",
    "Dai et al. PopPhy-CNN's (2019) algorithm creates Phylogenetic tree from OTUs and populates tree based on OTU abundances. This tree graph structure is then converted to a 2d Matrix by taking each parent node in the tree graph and pushing them all to the left and childrens' nodes in the same order from left to right the parents were ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(692, 127)\n",
      "There are 692 raw features...\n",
      "Building tree structure...\n",
      "Found tree file...\n",
      "Populating trees...\n",
      "There are 337 tree features...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.357585</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.498527</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.100589</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225184</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.465685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.014875  0.357585  0.046097  0.001915  0.078645  0.498527  0.002356   \n",
       "3  0.014875  0.100589  0.031811  0.000000  0.225184  0.046097  0.000000   \n",
       "4  0.014875  0.006186  0.094404  0.031811  0.000000  0.000000  0.000000   \n",
       "5  0.014875  0.006186  0.094404  0.000295  0.031517  0.000000  0.000000   \n",
       "6  0.014875  0.006186  0.094404  0.000295  0.031517  0.000000  0.000000   \n",
       "7  0.014875  0.000000  0.006186  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9    ...  580  581  582  583  584  585  586  587  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.001915  0.078645  0.465685  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.225184  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "6  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7  0.094404  0.000295  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "9  0.001473  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   588  589  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "5  0.0  0.0  \n",
       "6  0.0  0.0  \n",
       "7  0.0  0.0  \n",
       "8  0.0  0.0  \n",
       "9  0.0  0.0  \n",
       "\n",
       "[10 rows x 590 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_maps, raw_x, tree_x, raw_features, tree_features, labels, label_set, g, feature_df = prepare_data(path, data)\n",
    "\n",
    "pd.DataFrame(my_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets\n",
    "Splitting data into k training and k test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "input = my_maps\n",
    "target = tf.keras.utils.to_categorical(labels, 2, dtype='int64')\n",
    "    \n",
    "\n",
    "#shuffle dataset\n",
    "seed = np.random.randint(100)\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(input)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(target)\n",
    "\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(my_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(raw_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(tree_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "#create k training and k test sets\n",
    "groups_input = []\n",
    "groups_target = []\n",
    "k_size = len(input)//k\n",
    "start, end = 0, k_size\n",
    "for i in range(k):\n",
    "    if i == k-1:\n",
    "        group_input = input[start:]\n",
    "        group_target = target[start:]\n",
    "    else:\n",
    "        group_input = input[start:end]\n",
    "        group_target = target[start:end]\n",
    "    start += k_size\n",
    "    end += k_size\n",
    "    groups_input.append(group_input)\n",
    "    groups_target.append(group_target)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(k-1, -1, -1):\n",
    "    x_train.append(np.concatenate((groups_input[i-1], groups_input[i-2], groups_input[i-3], groups_input[i-4])))\n",
    "    y_train.append(np.concatenate((groups_target[i-1], groups_target[i-2], groups_target[i-3], groups_target[i-4])))\n",
    "\n",
    "    x_test.append(groups_input[i])\n",
    "    y_test.append(groups_target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### Training model\n",
    "Data is log transformed and then a MinMax transformation. Uses CNN that employs skipped residual identity blocks borrowed from the classic ResNet model then a FC Neural Network to make phenotype prediction. Model dimensions printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 225ms/step - loss: 3.5876 - accuracy: 0.6040 - val_loss: 2.4492 - val_accuracy: 0.6538\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 2.1127 - accuracy: 0.8317 - val_loss: 2.3216 - val_accuracy: 0.6538\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 1.8159 - accuracy: 0.9109 - val_loss: 2.1808 - val_accuracy: 0.6538\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.6126 - accuracy: 0.9406 - val_loss: 2.0335 - val_accuracy: 0.6538\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 1.3874 - accuracy: 0.9802 - val_loss: 1.8954 - val_accuracy: 0.7308\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 1.2257 - accuracy: 0.9802 - val_loss: 1.7771 - val_accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.0894 - accuracy: 1.0000 - val_loss: 1.6742 - val_accuracy: 0.6538\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.9721 - accuracy: 1.0000 - val_loss: 1.5787 - val_accuracy: 0.6154\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.8777 - accuracy: 1.0000 - val_loss: 1.4761 - val_accuracy: 0.6538\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.7952 - accuracy: 1.0000 - val_loss: 1.3961 - val_accuracy: 0.6538\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.7256 - accuracy: 1.0000 - val_loss: 1.3320 - val_accuracy: 0.6538\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.6643 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.6538\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.6113 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.6538\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5647 - accuracy: 1.0000 - val_loss: 1.1889 - val_accuracy: 0.6538\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.5234 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.6538\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.4869 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.6538\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.4544 - accuracy: 1.0000 - val_loss: 1.0888 - val_accuracy: 0.6538\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.4252 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.6538\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3990 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.6538\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3754 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.6538\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.3540 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.6538\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3346 - accuracy: 1.0000 - val_loss: 0.9841 - val_accuracy: 0.6538\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.3170 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.6538\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.6538\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.6154\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.6154\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2596 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.6538\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2479 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.6538\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.6923\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.7308\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.8077\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.7692\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2004 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.8077\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1926 - accuracy: 1.0000 - val_loss: 0.8563 - val_accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1853 - accuracy: 1.0000 - val_loss: 0.8487 - val_accuracy: 0.8077\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1785 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.8077\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1719 - accuracy: 1.0000 - val_loss: 0.8337 - val_accuracy: 0.8846\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.8846\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.1600 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8462\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.8846\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1396 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.8077\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1350 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.8077\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1307 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8077\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8462\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8077\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8077\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8077\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8462\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8462\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8462\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8462\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8462\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.8462\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.8462\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8462\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.8462\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8462\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8077\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.8077\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.8077\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8077\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8462\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.8462\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.8462\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.8462\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.8462\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.8462\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.8462\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8846\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8846\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8462\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8462\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8462\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.8462\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8462\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.8462\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8462\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8462\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8462\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.8462\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8462\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8462\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8462\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.8462\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8462\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8462\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.8462\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "auc_roc: 0.9150326797385621\n",
      "auc_pr: 0.8559344069147992\n",
      "f1_score: 0.8498834498834498\n",
      "mcc: 0.727606875108999\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[9.9935108e-01 6.4895971e-04]\n",
      " [5.8570197e-03 9.9414295e-01]\n",
      " [2.1013033e-01 7.8986961e-01]\n",
      " [3.2481791e-03 9.9675190e-01]\n",
      " [8.2797372e-01 1.7202628e-01]\n",
      " [9.8416036e-01 1.5839679e-02]\n",
      " [9.9989796e-01 1.0204127e-04]\n",
      " [7.4759406e-01 2.5240594e-01]\n",
      " [3.5071638e-03 9.9649280e-01]\n",
      " [1.4312722e-03 9.9856871e-01]\n",
      " [9.1374582e-01 8.6254150e-02]\n",
      " [9.9369675e-01 6.3032443e-03]\n",
      " [2.0632704e-03 9.9793673e-01]\n",
      " [1.1966502e-03 9.9880338e-01]\n",
      " [2.3509383e-03 9.9764901e-01]\n",
      " [7.5599372e-01 2.4400631e-01]\n",
      " [3.5703869e-04 9.9964297e-01]\n",
      " [7.8935031e-04 9.9921066e-01]\n",
      " [1.5125464e-03 9.9848753e-01]\n",
      " [9.8162568e-01 1.8374354e-02]\n",
      " [8.8530844e-01 1.1469155e-01]\n",
      " [9.9784657e-02 9.0021533e-01]\n",
      " [9.8749709e-01 1.2502947e-02]\n",
      " [1.9541234e-01 8.0458772e-01]\n",
      " [5.3951055e-01 4.6048939e-01]\n",
      " [6.4962089e-01 3.5037914e-01]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 590, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 590, 64)  576         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 10, 590, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 10, 590, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 10, 590, 64)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 10, 590, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 10, 590, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 10, 590, 64)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 590, 1)   65          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5900)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          590100      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,463\n",
      "Trainable params: 689,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 184ms/step - loss: 3.1238 - accuracy: 0.7426 - val_loss: 2.4658 - val_accuracy: 0.8462\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 2.1386 - accuracy: 0.9109 - val_loss: 2.2669 - val_accuracy: 0.7692\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 1.7576 - accuracy: 0.9703 - val_loss: 2.1041 - val_accuracy: 0.6538\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 1.5297 - accuracy: 0.9901 - val_loss: 1.9571 - val_accuracy: 0.6538\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 1.3724 - accuracy: 0.9802 - val_loss: 1.8192 - val_accuracy: 0.6538\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 1.2102 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0851 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.6923\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.9673 - accuracy: 1.0000 - val_loss: 1.4896 - val_accuracy: 0.6923\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.8731 - accuracy: 1.0000 - val_loss: 1.4053 - val_accuracy: 0.7308\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.7877 - accuracy: 1.0000 - val_loss: 1.3349 - val_accuracy: 0.8077\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.7157 - accuracy: 1.0000 - val_loss: 1.2753 - val_accuracy: 0.8077\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.6544 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.8077\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.6013 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.8077\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.5548 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.8077\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.5139 - accuracy: 1.0000 - val_loss: 1.1104 - val_accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.4779 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 0.8077\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.4459 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8077\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.4173 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.8077\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3917 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.7692\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.3685 - accuracy: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.7692\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.3475 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.7692\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3283 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.7692\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.7692\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2945 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.7692\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2796 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.7692\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2657 - accuracy: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.8077\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 0.8950 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8462\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.8731 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.8462\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2003 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.7692\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1917 - accuracy: 1.0000 - val_loss: 0.8358 - val_accuracy: 0.7692\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1759 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.7692\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1686 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7692\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1618 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7692\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.1554 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.7692\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1492 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.7692\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.7692\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.7692\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.7692\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.7692\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.7692\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.7692\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1142 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.7692\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.7692\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.7692\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8077\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8077\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8077\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8077\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8077\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.8077\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8077\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.7692\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8077\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 0.8077\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8077\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8077\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8077\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.8077\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8077\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.7692\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.8077\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.8077\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.8077\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.7692\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.8077\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8077\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.8077\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.8077\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8077\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8077\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8077\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8077\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.8077\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.8077\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8077\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8077\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8077\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8077\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.8077\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8077\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.7692\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.7692\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.7692\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8077\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.7692\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.7692\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.8077\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.8077\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.8077\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.7692\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.7692\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.8077\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.8077\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7692\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.7692\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "auc_roc: 0.8888888888888888\n",
      "auc_pr: 0.8888603546908046\n",
      "f1_score: 0.7692307692307693\n",
      "mcc: 0.49019607843137253\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[1.3882947e-03 9.9861175e-01]\n",
      " [9.8321825e-01 1.6781742e-02]\n",
      " [1.5631471e-03 9.9843687e-01]\n",
      " [1.1973783e-02 9.8802620e-01]\n",
      " [7.0414823e-01 2.9585174e-01]\n",
      " [1.3882111e-01 8.6117893e-01]\n",
      " [1.9719331e-02 9.8028070e-01]\n",
      " [5.7803253e-03 9.9421966e-01]\n",
      " [6.9967494e-04 9.9930036e-01]\n",
      " [2.6113027e-01 7.3886973e-01]\n",
      " [9.5335394e-04 9.9904662e-01]\n",
      " [1.8119742e-03 9.9818796e-01]\n",
      " [1.1316313e-03 9.9886835e-01]\n",
      " [1.1111921e-02 9.8888808e-01]\n",
      " [9.9956936e-01 4.3063308e-04]\n",
      " [8.5333627e-01 1.4666373e-01]\n",
      " [3.0204168e-01 6.9795835e-01]\n",
      " [1.8821000e-03 9.9811792e-01]\n",
      " [6.0289156e-01 3.9710847e-01]\n",
      " [9.1121765e-04 9.9908876e-01]\n",
      " [5.6151849e-01 4.3848145e-01]\n",
      " [9.6466690e-01 3.5333127e-02]\n",
      " [1.1705615e-03 9.9882942e-01]\n",
      " [8.4914947e-01 1.5085056e-01]\n",
      " [1.3730585e-03 9.9862695e-01]\n",
      " [7.8645420e-01 2.1354586e-01]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 590, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 590, 64)  576         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 10, 590, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 10, 590, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 10, 590, 64)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 10, 590, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 10, 590, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 10, 590, 64)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 590, 1)   65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 5900)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          590100      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,463\n",
      "Trainable params: 689,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 280ms/step - loss: 2.9886 - accuracy: 0.7059 - val_loss: 2.4593 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 2.1948 - accuracy: 0.8039 - val_loss: 2.2649 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 1.6880 - accuracy: 0.9216 - val_loss: 2.0299 - val_accuracy: 0.7600\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 1.4055 - accuracy: 0.9608 - val_loss: 1.8167 - val_accuracy: 0.7600\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 1.2152 - accuracy: 0.9902 - val_loss: 1.6593 - val_accuracy: 0.6400\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 1.0393 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.6400\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.9070 - accuracy: 1.0000 - val_loss: 1.4166 - val_accuracy: 0.6400\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.8026 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.7174 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.6445 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.7600\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.5831 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.7600\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.5309 - accuracy: 1.0000 - val_loss: 1.0974 - val_accuracy: 0.7600\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.4859 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.7600\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.4469 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.7600\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.4129 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.7200\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.7200\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3567 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.7200\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.3332 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.7200\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.7200\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2931 - accuracy: 1.0000 - val_loss: 0.8655 - val_accuracy: 0.7200\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.2759 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.7200\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.2602 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7200\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2459 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7200\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7200\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.7200\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.7600\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.1988 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.7600\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.1891 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.7600\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.1801 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.7600\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.1716 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.1637 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.7600\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1563 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.7600\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.7600\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.7600\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1366 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.7600\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1308 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.7600\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.7600\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.7600\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.7600\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.7600\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8400\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.8400\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.8400\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 92ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8400\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.8400\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8400\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8800\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8800\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8800\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8800\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.8800\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.8400\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8400\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.8800\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.8400\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.8400\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.8400\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 92ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8400\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.8400\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8400\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.8400\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.8400\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8400\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "auc_roc: 0.8958333333333334\n",
      "auc_pr: 0.8961923490637854\n",
      "f1_score: 0.8426666666666666\n",
      "mcc: 0.6782343280546951\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[9.57613826e-01 4.23862226e-02]\n",
      " [1.04630284e-03 9.98953760e-01]\n",
      " [2.42169626e-04 9.99757826e-01]\n",
      " [2.42299377e-03 9.97577012e-01]\n",
      " [2.73624668e-04 9.99726355e-01]\n",
      " [8.02214384e-01 1.97785661e-01]\n",
      " [9.99474108e-01 5.25945099e-04]\n",
      " [8.41894653e-05 9.99915838e-01]\n",
      " [9.99916911e-01 8.31181751e-05]\n",
      " [6.85860578e-04 9.99314189e-01]\n",
      " [3.72826442e-04 9.99627113e-01]\n",
      " [7.37110078e-01 2.62889922e-01]\n",
      " [1.85396671e-02 9.81460333e-01]\n",
      " [5.41992020e-04 9.99458015e-01]\n",
      " [1.00678019e-03 9.98993218e-01]\n",
      " [8.98612320e-01 1.01387642e-01]\n",
      " [9.41089153e-01 5.89108504e-02]\n",
      " [3.05055029e-04 9.99694943e-01]\n",
      " [3.58724385e-04 9.99641299e-01]\n",
      " [8.82258773e-01 1.17741205e-01]\n",
      " [4.15974588e-04 9.99584019e-01]\n",
      " [4.89427184e-04 9.99510527e-01]\n",
      " [9.87095833e-01 1.29042035e-02]\n",
      " [9.81034100e-01 1.89658701e-02]\n",
      " [9.97219801e-01 2.78015761e-03]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 10, 590, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 590, 64)  576         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10, 590, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 10, 590, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10, 590, 64)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 10, 590, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 10, 590, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 10, 590, 64)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 590, 1)   65          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 5900)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          590100      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,463\n",
      "Trainable params: 689,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 181ms/step - loss: 3.4711 - accuracy: 0.5588 - val_loss: 2.3940 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 2.2110 - accuracy: 0.8235 - val_loss: 2.2568 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.8300 - accuracy: 0.9216 - val_loss: 2.1232 - val_accuracy: 0.6800\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 1.5844 - accuracy: 0.9608 - val_loss: 1.9922 - val_accuracy: 0.6800\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 1.3966 - accuracy: 0.9902 - val_loss: 1.8734 - val_accuracy: 0.6800\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 1.2508 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.6800\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 1.1396 - accuracy: 1.0000 - val_loss: 1.6573 - val_accuracy: 0.6800\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 1.0374 - accuracy: 1.0000 - val_loss: 1.5628 - val_accuracy: 0.6800\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.9482 - accuracy: 1.0000 - val_loss: 1.4782 - val_accuracy: 0.6800\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.8692 - accuracy: 1.0000 - val_loss: 1.4029 - val_accuracy: 0.6800\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.7986 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.6800\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.7358 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.6800\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.6797 - accuracy: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.6800\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.6297 - accuracy: 1.0000 - val_loss: 1.1783 - val_accuracy: 0.6800\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.5847 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.6800\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5445 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.6800\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5083 - accuracy: 1.0000 - val_loss: 1.0667 - val_accuracy: 0.6800\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.4758 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.6800\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.4463 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.6800\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.4197 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.6800\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3956 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.6800\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 0.9413 - val_accuracy: 0.6800\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3538 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.6800\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3356 - accuracy: 1.0000 - val_loss: 0.9059 - val_accuracy: 0.6800\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.3188 - accuracy: 1.0000 - val_loss: 0.8908 - val_accuracy: 0.6800\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3036 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.6800\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2895 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.6800\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2765 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.6800\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.2644 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.6800\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2533 - accuracy: 1.0000 - val_loss: 0.8305 - val_accuracy: 0.6800\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.6800\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.6800\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.6800\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.6800\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.6800\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2001 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.6800\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.1930 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.6800\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.6800\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.6800\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.6800\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.6800\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1575 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.6800\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.1525 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.6800\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.7200\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1432 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.7200\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.7200\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1346 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.7200\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.7200\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 108ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.7200\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.7200\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.7600\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.1128 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.7200\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.7200\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.7600\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.7600\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.7600\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.7200\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.5898 - val_accuracy: 0.7200\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.7200\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.7600\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.7600\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.7600\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.7600\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8400\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.8400\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8400\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8400\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.8400\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.8400\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.8400\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8400\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8400\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8400\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.8400\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.8800\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.8400\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.8800\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8800\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.8400\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8400\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "auc_roc: 0.9117647058823529\n",
      "auc_pr: 0.9077088767861168\n",
      "f1_score: 0.8217543859649123\n",
      "mcc: 0.6362090102803518\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1.0788728e-03 9.9892116e-01]\n",
      " [1.7710204e-03 9.9822897e-01]\n",
      " [7.7143908e-05 9.9992287e-01]\n",
      " [3.7340572e-01 6.2659425e-01]\n",
      " [4.5395467e-01 5.4604530e-01]\n",
      " [9.3478329e-02 9.0652168e-01]\n",
      " [1.4841498e-02 9.8515850e-01]\n",
      " [1.5280374e-02 9.8471963e-01]\n",
      " [9.6392274e-01 3.6077309e-02]\n",
      " [1.3547428e-02 9.8645252e-01]\n",
      " [2.8262138e-03 9.9717385e-01]\n",
      " [3.3356573e-02 9.6664345e-01]\n",
      " [1.4807171e-03 9.9851924e-01]\n",
      " [1.3570826e-03 9.9864286e-01]\n",
      " [7.2593045e-01 2.7406958e-01]\n",
      " [2.1273904e-01 7.8726095e-01]\n",
      " [1.7979424e-03 9.9820215e-01]\n",
      " [9.9120587e-01 8.7941084e-03]\n",
      " [1.7629123e-03 9.9823713e-01]\n",
      " [8.4405788e-04 9.9915600e-01]\n",
      " [4.4467252e-01 5.5532748e-01]\n",
      " [4.4747177e-04 9.9955255e-01]\n",
      " [9.4745570e-01 5.2544307e-02]\n",
      " [7.1707368e-03 9.9282926e-01]\n",
      " [7.8347296e-04 9.9921656e-01]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 590, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 590, 64)  576         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 10, 590, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 10, 590, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 10, 590, 64)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 10, 590, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 10, 590, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 10, 590, 64)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 590, 1)   65          ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 5900)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          590100      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,463\n",
      "Trainable params: 689,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 188ms/step - loss: 3.5039 - accuracy: 0.6569 - val_loss: 2.4621 - val_accuracy: 0.7200\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 2.6247 - accuracy: 0.6765 - val_loss: 2.3537 - val_accuracy: 0.7600\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 1.8335 - accuracy: 0.9314 - val_loss: 2.2255 - val_accuracy: 0.7200\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 1.6748 - accuracy: 0.9608 - val_loss: 2.1947 - val_accuracy: 0.3600\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 1.5010 - accuracy: 0.9804 - val_loss: 2.1386 - val_accuracy: 0.3600\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 1.3918 - accuracy: 0.9804 - val_loss: 2.0359 - val_accuracy: 0.3600\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 1.2351 - accuracy: 1.0000 - val_loss: 1.9453 - val_accuracy: 0.3600\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 1.1351 - accuracy: 1.0000 - val_loss: 1.8430 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 1.0465 - accuracy: 1.0000 - val_loss: 1.7584 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.9684 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.3600\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.8950 - accuracy: 1.0000 - val_loss: 1.6778 - val_accuracy: 0.3600\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.8318 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.3200\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.7740 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.3200\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.7220 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.3200\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.6751 - accuracy: 1.0000 - val_loss: 1.5216 - val_accuracy: 0.3200\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.6323 - accuracy: 1.0000 - val_loss: 1.4836 - val_accuracy: 0.3200\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5932 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.3200\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.5574 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.3200\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.5243 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.3200\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.4940 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.3200\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.4661 - accuracy: 1.0000 - val_loss: 1.3110 - val_accuracy: 0.3200\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.4402 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.3200\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.4164 - accuracy: 1.0000 - val_loss: 1.2387 - val_accuracy: 0.3200\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3942 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.3200\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.3200\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3547 - accuracy: 1.0000 - val_loss: 1.1453 - val_accuracy: 0.3200\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.3370 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.3200\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3205 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.3600\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3051 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.3600\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2907 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.3600\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2773 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.3600\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.3600\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.3600\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.9225 - val_accuracy: 0.4800\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.8996 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.6400\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2044 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.6800\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1962 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1886 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.6800\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 0.8113 - val_accuracy: 0.6800\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1746 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.6800\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.1561 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1402 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.7600\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.1111 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8400\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8400\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.8400\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.8800\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8800\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8800\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8800\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8800\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8800\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8800\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.8800\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.8800\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.8800\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8400\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8400\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.8400\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.8400\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.8400\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8400\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.8400\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x28f3719d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "auc_roc: 1.0\n",
      "auc_pr: 1.0\n",
      "f1_score: 0.8453333333333333\n",
      "mcc: 0.7140055472954167\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[9.8349184e-01 1.6508155e-02]\n",
      " [7.2840017e-01 2.7159986e-01]\n",
      " [9.9869949e-01 1.3005433e-03]\n",
      " [5.8963606e-03 9.9410361e-01]\n",
      " [1.0333303e-03 9.9896669e-01]\n",
      " [9.2201197e-01 7.7988036e-02]\n",
      " [9.9980325e-01 1.9676938e-04]\n",
      " [6.6256727e-04 9.9933743e-01]\n",
      " [2.8947794e-03 9.9710518e-01]\n",
      " [9.9412507e-01 5.8749393e-03]\n",
      " [9.9971211e-01 2.8787143e-04]\n",
      " [6.6751993e-01 3.3248013e-01]\n",
      " [9.1480207e-01 8.5197926e-02]\n",
      " [3.2405837e-03 9.9675947e-01]\n",
      " [9.1226107e-01 8.7738968e-02]\n",
      " [1.3894407e-03 9.9861056e-01]\n",
      " [9.8051596e-04 9.9901950e-01]\n",
      " [7.4432597e-02 9.2556739e-01]\n",
      " [9.8195893e-01 1.8041061e-02]\n",
      " [5.2373414e-04 9.9947625e-01]\n",
      " [1.4329804e-03 9.9856704e-01]\n",
      " [7.3455850e-04 9.9926549e-01]\n",
      " [6.7072558e-01 3.2927445e-01]\n",
      " [1.1409562e-02 9.8859042e-01]\n",
      " [1.8365836e-02 9.8163420e-01]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10, 590, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 590, 64)  576         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 10, 590, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 10, 590, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 10, 590, 64)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 10, 590, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 590, 64)  32832       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 590, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 10, 590, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 10, 590, 64)  0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 590, 1)   65          ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 5900)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          590100      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,463\n",
      "Trainable params: 689,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_lst = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     x_train1 = x_train[i]\n",
    "#     y_train1 = y_train[i]\n",
    "#     x_test1 = x_test[i]\n",
    "#     y_test1 = y_test[i]\n",
    "\n",
    "#     model = ResNet(height = x_train1.shape[1], width = x_train1.shape[2], channels = 1, classes = 2)\n",
    "#     model.init_model()\n",
    "\n",
    "#     model.train(x_train1, y_train1, x_test1, y_test1, dataset, use_weights = False)\n",
    "#     y_pred = model.predict(x_test1)\n",
    "#     auc_roc, auc_pr, f1, mcc = model.evaluate(y_test1, y_pred)\n",
    "#     data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    \n",
    "#     #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "\n",
    "#     print(y_test1)\n",
    "#     print(y_pred)\n",
    "    \n",
    "# print(model.model.summary())\n",
    "\n",
    "\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "tree_row = my_maps.shape[1]\n",
    "tree_col = my_maps.shape[2]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "fold = 0\n",
    "for train_index, test_index in skf.split(my_maps, labels):\n",
    "    train_x, test_x = my_maps[train_index,:,:], my_maps[test_index,:,:]\n",
    "    train_y, test_y = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        \n",
    "    train_x = np.log(train_x + 1)\n",
    "    test_x = np.log(test_x + 1)\n",
    "        \n",
    "    c_prob = [0] * len(np.unique(labels))\n",
    "    train_weights = []\n",
    "\n",
    "    for l in np.unique(labels):\n",
    "        a = float(len(labels))\n",
    "        b = 2.0 * float((np.sum(labels==l)))\n",
    "        c_prob[int(l)] = a/b\n",
    "\n",
    "    c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "    for l in np.argmax(train_y, 1):\n",
    "        train_weights.append(c_prob[int(l)])\n",
    "    train_weights = np.array(train_weights)\n",
    "        \n",
    "    scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "    train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "    test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "    train = [train_x, train_y]\n",
    "    test = [test_x, test_y]\n",
    "\n",
    "    x_train1 = train_x\n",
    "    y_train1 = train_y\n",
    "    x_test1 = test_x\n",
    "    y_test1 = test_y\n",
    "        \n",
    "#         y_train1 = train_y\n",
    "#         y_test1 = test_y\n",
    "        \n",
    "#         x_train1 = np.zeros(train_x.shape)\n",
    "#         x_train1[train_x != 0] = 1\n",
    "        \n",
    "#         x_test1 = np.zeros(test_x.shape)\n",
    "#         x_test1[test_x != 0] = 1\n",
    "        \n",
    "        # for i in range(len(train_x)):\n",
    "        #     for j in range(len(test_x)):\n",
    "        #         if np.array_equal(train_x[i], test_x[j]):\n",
    "        #             print('train')\n",
    "        #             print(train_x[i])\n",
    "        #             print('test')\n",
    "        #             print(test_x[j])\n",
    "        \n",
    "        \n",
    "    model = ResNet(height = train_x.shape[1], width = train_x.shape[2], channels = 1, classes = 2)\n",
    "    model.init_model()\n",
    "    model.train(train_x, train_y, test_x, y_test1, dataset, use_weights = False)\n",
    "    y_pred = model.predict(test_x)\n",
    "    auc_roc, auc_pr, f1, mcc = model.evaluate(test_y, y_pred)\n",
    "    data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "    print(test_y)\n",
    "    print(y_pred)\n",
    "    print(model.model.summary())\n",
    "    \n",
    "    fold += 1\n",
    "#run += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Accuracy Metrics and Saving Metrics\n",
    "\n",
    "Option to save results of all k folds and weights of last model into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc(roc)</th>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc(pr)</th>\n",
       "      <td>0.855934</td>\n",
       "      <td>0.888860</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>0.907709</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.849883</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.821754</td>\n",
       "      <td>0.845333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.727607</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.678234</td>\n",
       "      <td>0.636209</td>\n",
       "      <td>0.714006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3         4         5\n",
       "auc(roc)  0.915033  0.888889  0.895833  0.911765  1.000000\n",
       "auc(pr)   0.855934  0.888860  0.896192  0.907709  1.000000\n",
       "f1        0.849883  0.769231  0.842667  0.821754  0.845333\n",
       "mcc       0.727607  0.490196  0.678234  0.636209  0.714006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [str(i) for i in range(1,k+1)]    \n",
    "results_df = pd.DataFrame(data_lst, columns = ['auc(roc)', 'auc(pr)', 'f1', 'mcc'])\n",
    "results_df = results_df.transpose()\n",
    "results_df.columns = col\n",
    "\n",
    "#results_df.to_csv(path + \"/results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Weights\n",
    "\n",
    "Option to save model weights of last model in k fold into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.model.save_weights(path + \"/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
