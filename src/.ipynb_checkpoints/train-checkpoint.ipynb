{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import abspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_network import generate_network\n",
    "from utils.prepare_data import prepare_data\n",
    "from utils.popphy_io import save_params, load_params\n",
    "from utils.popphy_io import get_stat, get_stat_dict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from models.PopPhy import PopPhyCNN\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "#from models.PopPhy2 import ResNet\n",
    "from models.PopPhy2 import ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Reading Configuration\n",
    "Configuring which data to read in, minimun threshold needed in an OTU (individual sample must have at least set threshold relative abundance), and how many k folds for k fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'skg-wt-t1'\n",
    "threshold = 0\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features\n",
    "Reduce amount of OTU features by filtering out OTUs that contain no individual sample with a relative abundance greater than the set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Bacteroidaceae|g__Bacteroides|s__Bacteroides_acidifaciens</th>\n",
       "      <td>35</td>\n",
       "      <td>712</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>609</td>\n",
       "      <td>1129</td>\n",
       "      <td>397</td>\n",
       "      <td>209</td>\n",
       "      <td>562</td>\n",
       "      <td>284</td>\n",
       "      <td>1923</td>\n",
       "      <td>989</td>\n",
       "      <td>815</td>\n",
       "      <td>1254</td>\n",
       "      <td>2941</td>\n",
       "      <td>1171</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>2986</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_murinus</th>\n",
       "      <td>294</td>\n",
       "      <td>258</td>\n",
       "      <td>318</td>\n",
       "      <td>258</td>\n",
       "      <td>403</td>\n",
       "      <td>446</td>\n",
       "      <td>914</td>\n",
       "      <td>761</td>\n",
       "      <td>6</td>\n",
       "      <td>1150</td>\n",
       "      <td>664</td>\n",
       "      <td>4588</td>\n",
       "      <td>1151</td>\n",
       "      <td>1660</td>\n",
       "      <td>3936</td>\n",
       "      <td>920</td>\n",
       "      <td>721</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_johnsonii</th>\n",
       "      <td>15</td>\n",
       "      <td>135</td>\n",
       "      <td>92</td>\n",
       "      <td>470</td>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1761</td>\n",
       "      <td>3105</td>\n",
       "      <td>866</td>\n",
       "      <td>679</td>\n",
       "      <td>430</td>\n",
       "      <td>2288</td>\n",
       "      <td>1161</td>\n",
       "      <td>2464</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Rikenellaceae|g__Alistipes|s__Alistipes_unclassified</th>\n",
       "      <td>46</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>373</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>971</td>\n",
       "      <td>518</td>\n",
       "      <td>181</td>\n",
       "      <td>130</td>\n",
       "      <td>998</td>\n",
       "      <td>777</td>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__Lachnospiraceae NK4A136 group|s__Lachnospiraceae NK4A136 group_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Bacteroidaceae|g__Bacteroides|s__Bacteroides_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     1    2    3    4    5   \\\n",
       "0                                                                             \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   35  712  107    0  616   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0    0    9    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  294  258  318  258  403   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   15  135   92  470  125   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   46  106   12  373   52   \n",
       "...                                                 ...  ...  ...  ...  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0    0    0    0    0   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...    0    0    0    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0    0    0    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0    0    0    0    0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0    0    0    0    0   \n",
       "\n",
       "                                                     6     7    8    9     10  \\\n",
       "0                                                                               \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  609  1129  397  209   562   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  446   914  761    6  1150   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   54    30   26   52  1761   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   73    98    0   13   971   \n",
       "...                                                 ...   ...  ...  ...   ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0     0    0    0     0   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0     0    0    0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...    0     0    0    0     0   \n",
       "\n",
       "                                                      11    12    13    14  \\\n",
       "0                                                                            \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   284  1923   989   815   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0   355     0  2986   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   664  4588  1151  1660   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  3105   866   679   430   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   518   181   130   998   \n",
       "...                                                  ...   ...   ...   ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...     0     0     0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0   \n",
       "\n",
       "                                                      15    16    17    18  \n",
       "0                                                                           \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  1254  2941  1171   716  \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...     0     4     2     0  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  3936   920   721   509  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  2288  1161  2464  1215  \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   777    92    28   185  \n",
       "...                                                  ...   ...   ...   ...  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0  \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...     0     0     0     0  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...     0     0     0     0  \n",
       "\n",
       "[1379 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/\" + dataset\n",
    "data = pd.read_csv(path + '/abundance.tsv', index_col=0, sep='\\t', header=None)\n",
    "to_drop = data.loc[(data < threshold).all(axis=1)]\n",
    "data = data.drop(to_drop.index)\n",
    "\n",
    "data = data.groupby(data.index).sum()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2d Matrix Representing OTU Data\n",
    "Dai et al. PopPhy-CNN's (2019) algorithm creates Phylogenetic tree from OTUs and populates tree based on OTU abundances. This tree graph structure is then converted to a 2d Matrix by taking each parent node in the tree graph and pushing them all to the left and childrens' nodes in the same order from left to right the parents were ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1379, 18)\n",
      "There are 1379 raw features...\n",
      "Building tree structure...\n",
      "Tree file not found...\n",
      "Constructing tree..\n",
      "Pruning Tree...\n",
      "Populating trees...\n",
      "There are 432 tree features...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1131</th>\n",
       "      <th>1132</th>\n",
       "      <th>1133</th>\n",
       "      <th>1134</th>\n",
       "      <th>1135</th>\n",
       "      <th>1136</th>\n",
       "      <th>1137</th>\n",
       "      <th>1138</th>\n",
       "      <th>1139</th>\n",
       "      <th>1140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.357585</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.498527</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.100589</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225184</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.465685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.014875  0.357585  0.046097  0.001915  0.078645  0.498527  0.002356   \n",
       "3   0.014875  0.100589  0.031811  0.000000  0.225184  0.046097  0.000000   \n",
       "4   0.014875  0.006186  0.094404  0.031811  0.000000  0.000000  0.000000   \n",
       "5   0.014875  0.006186  0.094404  0.000295  0.031517  0.000000  0.000000   \n",
       "6   0.014875  0.006186  0.094404  0.000295  0.031517  0.000000  0.000000   \n",
       "7   0.014875  0.000000  0.006186  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9     ...  1131  1132  1133  1134  1135  1136  \\\n",
       "0   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3   0.001915  0.078645  0.465685  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "5   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7   0.094404  0.000295  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "10  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    1137  1138  1139  1140  \n",
       "0    0.0   0.0   0.0   0.0  \n",
       "1    0.0   0.0   0.0   0.0  \n",
       "2    0.0   0.0   0.0   0.0  \n",
       "3    0.0   0.0   0.0   0.0  \n",
       "4    0.0   0.0   0.0   0.0  \n",
       "5    0.0   0.0   0.0   0.0  \n",
       "6    0.0   0.0   0.0   0.0  \n",
       "7    0.0   0.0   0.0   0.0  \n",
       "8    0.0   0.0   0.0   0.0  \n",
       "9    0.0   0.0   0.0   0.0  \n",
       "10   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[11 rows x 1141 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_maps, raw_x, tree_x, raw_features, tree_features, labels, label_set, g, feature_df = prepare_data(path, data)\n",
    "\n",
    "# norms = np.linalg.norm(my_maps, axis=2, keepdims=True)\n",
    "# my_maps = my_maps / norms\n",
    "pd.DataFrame(my_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets\n",
    "Splitting data into k training and k test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "input = my_maps\n",
    "target = tf.keras.utils.to_categorical(labels, 2, dtype='int64')\n",
    "    \n",
    "\n",
    "#shuffle dataset\n",
    "seed = np.random.randint(100)\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(input)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(target)\n",
    "\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(my_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(raw_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(tree_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "#create k training and k test sets\n",
    "groups_input = []\n",
    "groups_target = []\n",
    "k_size = len(input)//k\n",
    "start, end = 0, k_size\n",
    "for i in range(k):\n",
    "    if i == k-1:\n",
    "        group_input = input[start:]\n",
    "        group_target = target[start:]\n",
    "    else:\n",
    "        group_input = input[start:end]\n",
    "        group_target = target[start:end]\n",
    "    start += k_size\n",
    "    end += k_size\n",
    "    groups_input.append(group_input)\n",
    "    groups_target.append(group_target)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(k-1, -1, -1):\n",
    "    x_train.append(np.concatenate((groups_input[i-1], groups_input[i-2], groups_input[i-3], groups_input[i-4])))\n",
    "    y_train.append(np.concatenate((groups_target[i-1], groups_target[i-2], groups_target[i-3], groups_target[i-4])))\n",
    "\n",
    "    x_test.append(groups_input[i])\n",
    "    y_test.append(groups_target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### Training model\n",
    "Data is log transformed and then a MinMax transformation. Uses CNN that employs skipped residual identity blocks borrowed from the classic ResNet model then a FC Neural Network to make phenotype prediction. Model dimensions printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 3s 596ms/step - loss: 3.0471 - accuracy: 0.3571 - val_loss: 2.6127 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 2.3585 - accuracy: 0.9286 - val_loss: 2.1715 - val_accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.8477 - accuracy: 1.0000 - val_loss: 1.8502 - val_accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.4927 - accuracy: 1.0000 - val_loss: 1.6295 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.2576 - accuracy: 1.0000 - val_loss: 1.4900 - val_accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 1.1071 - accuracy: 1.0000 - val_loss: 1.4024 - val_accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.9854 - accuracy: 1.0000 - val_loss: 1.3472 - val_accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.9174 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.8793 - accuracy: 1.0000 - val_loss: 1.2748 - val_accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.8411 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.7965 - accuracy: 1.0000 - val_loss: 1.2213 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.7581 - accuracy: 1.0000 - val_loss: 1.1905 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.7277 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.7500\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.6946 - accuracy: 1.0000 - val_loss: 1.1345 - val_accuracy: 0.7500\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.6590 - accuracy: 1.0000 - val_loss: 1.1113 - val_accuracy: 0.7500\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.6292 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.7500\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.6053 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.7500\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.5828 - accuracy: 1.0000 - val_loss: 1.0556 - val_accuracy: 0.7500\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.5676 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.7500\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.5398 - accuracy: 1.0000 - val_loss: 1.0281 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.5251 - accuracy: 1.0000 - val_loss: 1.0161 - val_accuracy: 0.7500\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.5049 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.7500\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4929 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.7500\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.4740 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.7500\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.4623 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.7500\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4463 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.7500\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.4326 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.7500\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.4167 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.7500\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.4053 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3915 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3709 - accuracy: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3416 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3334 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.7500\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3247 - accuracy: 1.0000 - val_loss: 0.8790 - val_accuracy: 0.7500\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2991 - accuracy: 1.0000 - val_loss: 0.8622 - val_accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 0.8546 - val_accuracy: 0.5000\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2785 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.7500\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.5000\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2601 - accuracy: 1.0000 - val_loss: 0.8224 - val_accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2545 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.7500\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7500\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2381 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7500\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2316 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7500\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.7500\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.7500\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.7500\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.7500\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.7500\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1999 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.7500\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1971 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.7500\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1911 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.7500\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1889 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.7500\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1849 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.7500\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.7500\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.1784 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.7500\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.1750 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.7500\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.7500\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1686 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1610 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.7500\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1547 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.7500\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1528 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.7500\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.7500\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.7500\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.7500\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1407 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.7500\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.7500\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.7500\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.7500\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.7500\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.7500\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.7500\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.7500\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.7500\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.7500\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.7500\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.7500\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.7500\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.7500\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 195ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "auc_roc: 1.0\n",
      "auc_pr: 1.0\n",
      "f1_score: 1.0\n",
      "mcc: 1.0\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[0.93773323 0.06226676]\n",
      " [0.3440609  0.65593916]\n",
      " [0.00586852 0.9941315 ]\n",
      " [0.6147728  0.38522717]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 11, 1141, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 11, 1141, 64  576         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 11, 1141, 64  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 11, 1141, 64  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                )                                 'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 11, 1141, 64  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 11, 1141, 64  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 11, 1141, 64  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                )                                 'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 11, 1141, 64  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 11, 1141, 1)  65          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 12551)        0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          1255200     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 32)           3232        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            66          ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,659\n",
      "Trainable params: 1,358,147\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 2s 371ms/step - loss: 3.0749 - accuracy: 0.5714 - val_loss: 2.6175 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 191ms/step - loss: 2.4002 - accuracy: 0.7857 - val_loss: 2.1755 - val_accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.8944 - accuracy: 0.9286 - val_loss: 1.8558 - val_accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.5193 - accuracy: 1.0000 - val_loss: 1.6336 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.2935 - accuracy: 1.0000 - val_loss: 1.4910 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 1.1181 - accuracy: 1.0000 - val_loss: 1.4075 - val_accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 1.0311 - accuracy: 1.0000 - val_loss: 1.3554 - val_accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.9624 - accuracy: 1.0000 - val_loss: 1.3173 - val_accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.9049 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.8610 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.8272 - accuracy: 1.0000 - val_loss: 1.2366 - val_accuracy: 0.5000\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.7934 - accuracy: 1.0000 - val_loss: 1.2105 - val_accuracy: 0.5000\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.7578 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.7500\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.7097 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.7500\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.6904 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.7500\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.6543 - accuracy: 1.0000 - val_loss: 1.1267 - val_accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.6287 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.6040 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.5849 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.5612 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.5420 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.7500\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.5258 - accuracy: 1.0000 - val_loss: 1.0402 - val_accuracy: 0.7500\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.5090 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.7500\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.4941 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.7500\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.4763 - accuracy: 1.0000 - val_loss: 1.0053 - val_accuracy: 0.7500\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.4697 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.7500\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.4522 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.7500\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.4367 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.7500\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.4282 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4191 - accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.4064 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3913 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3828 - accuracy: 1.0000 - val_loss: 0.9264 - val_accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3747 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3624 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3511 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.7500\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3464 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.7500\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3353 - accuracy: 1.0000 - val_loss: 0.8863 - val_accuracy: 0.7500\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.8789 - val_accuracy: 0.7500\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.7500\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.8645 - val_accuracy: 0.7500\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3034 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.7500\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2966 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.7500\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2912 - accuracy: 1.0000 - val_loss: 0.8439 - val_accuracy: 0.7500\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.8371 - val_accuracy: 0.7500\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.7500\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2674 - accuracy: 1.0000 - val_loss: 0.8251 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.8193 - val_accuracy: 0.7500\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2575 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.7500\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7500\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2461 - accuracy: 1.0000 - val_loss: 0.8021 - val_accuracy: 0.7500\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.7500\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.7500\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2306 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.7500\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2260 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.7500\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.7768 - val_accuracy: 0.7500\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.7500\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.7500\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2052 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.7500\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2037 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.7500\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1960 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.7500\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1926 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.7500\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.7500\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1858 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.7500\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.7500\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1782 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1711 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.7500\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.7500\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1639 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.7500\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.1608 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.7500\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1606 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.7500\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.7500\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.7500\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.7500\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.7500\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1445 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.7500\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1431 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.7500\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.7500\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.7500\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1142 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.7500\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.7500\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.7500\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.7500\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.7500\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.7500\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 0.7500\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.7500\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.7500\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.7500\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.7500\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.7500\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.7500\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.7500\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.7500\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.7500\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.7500\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.7500\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.7500\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.7500\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.7500\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.7500\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.7500\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.7500\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.7500\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.7500\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.7500\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.7500\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.7500\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.7500\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.7500\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.7500\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.7500\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.7500\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.7500\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.7500\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.7500\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.7500\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "auc_roc: 0.75\n",
      "auc_pr: 0.8333333333333333\n",
      "f1_score: 0.7333333333333334\n",
      "mcc: 0.5773502691896258\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[0.9828446  0.01715547]\n",
      " [0.99735904 0.00264102]\n",
      " [0.01609057 0.9839094 ]\n",
      " [0.73712987 0.26287013]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 11, 1141, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 11, 1141, 64  576         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 11, 1141, 64  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_4[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 11, 1141, 64  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                )                                 'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 11, 1141, 64  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 11, 1141, 64  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 11, 1141, 64  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                )                                 'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 11, 1141, 64  0           ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 11, 1141, 1)  65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 12551)        0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          1255200     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 32)           3232        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            66          ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,659\n",
      "Trainable params: 1,358,147\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 2s 310ms/step - loss: 3.0624 - accuracy: 0.3571 - val_loss: 2.6532 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 2.4640 - accuracy: 0.7143 - val_loss: 2.2381 - val_accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 2.0273 - accuracy: 0.8571 - val_loss: 1.9051 - val_accuracy: 0.7500\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 1.7215 - accuracy: 0.9286 - val_loss: 1.6648 - val_accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 1.4217 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 1.2696 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.1353 - accuracy: 1.0000 - val_loss: 1.3155 - val_accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 1.0314 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.9599 - accuracy: 1.0000 - val_loss: 1.2258 - val_accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.9050 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.8705 - accuracy: 1.0000 - val_loss: 1.1703 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.8208 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.7699 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.7434 - accuracy: 1.0000 - val_loss: 1.0935 - val_accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.7116 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.6793 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.6512 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.6251 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5968 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.5836 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5628 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.7500\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.5447 - accuracy: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.7500\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.5226 - accuracy: 1.0000 - val_loss: 0.9356 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.5023 - accuracy: 1.0000 - val_loss: 0.9240 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4906 - accuracy: 1.0000 - val_loss: 0.9133 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.4690 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.4575 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4476 - accuracy: 1.0000 - val_loss: 0.8829 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.4349 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.4220 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 213ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3946 - accuracy: 1.0000 - val_loss: 0.8480 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3847 - accuracy: 1.0000 - val_loss: 0.8396 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 192ms/step - loss: 0.3769 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3645 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3536 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3467 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3372 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3283 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3271 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3126 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3068 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2984 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2894 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2832 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2638 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2581 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2401 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2355 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2062 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2055 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2011 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1955 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1903 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1843 - accuracy: 1.0000 - val_loss: 0.6444 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1818 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1753 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 210ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1567 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1543 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1489 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1488 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.1431 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.5235 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 215ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1228 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 185ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 186ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 200ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "auc_roc: 1.0\n",
      "auc_pr: 1.0\n",
      "f1_score: 1.0\n",
      "mcc: 1.0\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[0.9976234  0.0023766 ]\n",
      " [0.07587587 0.9241241 ]\n",
      " [0.03229075 0.96770924]\n",
      " [0.97760415 0.02239582]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 11, 1141, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 11, 1141, 64  576         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 11, 1141, 64  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 11, 1141, 64  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                )                                 'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 11, 1141, 64  0           ['add_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11, 1141, 64  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_10[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 11, 1141, 64  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11, 1141, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 11, 1141, 1)  65          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 12551)        0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          1255200     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 32)           3232        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            66          ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,659\n",
      "Trainable params: 1,358,147\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 2.9987 - accuracy: 0.6000 - val_loss: 2.5867 - val_accuracy: 0.6667\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 195ms/step - loss: 2.3115 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 214ms/step - loss: 1.9098 - accuracy: 0.8667 - val_loss: 1.8277 - val_accuracy: 0.6667\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 1.5478 - accuracy: 1.0000 - val_loss: 1.6332 - val_accuracy: 0.3333\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 1.3414 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 1.1734 - accuracy: 1.0000 - val_loss: 1.4242 - val_accuracy: 0.3333\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.0481 - accuracy: 1.0000 - val_loss: 1.3767 - val_accuracy: 0.3333\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.9858 - accuracy: 1.0000 - val_loss: 1.3429 - val_accuracy: 0.3333\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.9147 - accuracy: 1.0000 - val_loss: 1.3021 - val_accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.8789 - accuracy: 1.0000 - val_loss: 1.2663 - val_accuracy: 0.6667\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.8219 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.7818 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.7427 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.7052 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.6755 - accuracy: 1.0000 - val_loss: 1.1403 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.6373 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.6667\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.6105 - accuracy: 1.0000 - val_loss: 1.1046 - val_accuracy: 0.6667\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.5866 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.5718 - accuracy: 1.0000 - val_loss: 1.0695 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.5450 - accuracy: 1.0000 - val_loss: 1.0529 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.5252 - accuracy: 1.0000 - val_loss: 1.0376 - val_accuracy: 0.6667\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.5116 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.6667\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.4945 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6667\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.4768 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.6667\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.4603 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.6667\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.4423 - accuracy: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.6667\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.4327 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.6667\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.4220 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 0.9504 - val_accuracy: 0.6667\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3939 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.6667\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.3811 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.6667\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3718 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.6667\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3598 - accuracy: 1.0000 - val_loss: 0.9213 - val_accuracy: 0.6667\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 186ms/step - loss: 0.3519 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3396 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.6667\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3045 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.6667\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.6667\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.6667\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.6667\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.6667\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2660 - accuracy: 1.0000 - val_loss: 0.8481 - val_accuracy: 0.6667\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 0.6667\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 0.8370 - val_accuracy: 0.6667\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2402 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.6667\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 0.8194 - val_accuracy: 0.6667\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.6667\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.6667\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.6667\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.6667\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.6667\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2005 - accuracy: 1.0000 - val_loss: 0.7866 - val_accuracy: 0.6667\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1972 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.6667\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.6667\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.6667\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1836 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.6667\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.6667\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1759 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.6667\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1734 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.6667\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1685 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.6667\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.6667\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1636 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.6667\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1612 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.6667\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.6667\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.6667\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1497 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.6667\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1476 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.6667\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1463 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.6667\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.6667\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.6667\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.6667\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.6667\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.6667\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1302 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.6667\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.6667\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.6667\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.6667\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.6667\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.6667\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.6667\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.6667\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.6667\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.6667\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1129 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.6667\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.6667\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.6667\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.6667\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.6667\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.6667\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.6667\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.6667\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.6667\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.6667\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.6667\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.6667\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.6667\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.6667\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.6667\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.6667\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 0.6667\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.6667\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.6667\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.6667\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.6667\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.6667\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.6667\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.6667\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.6667\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.6667\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.6667\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.6667\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.6667\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.6667\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.6667\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 1s 269ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.6667\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.6667\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.6667\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.6667\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.6667\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.6667\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.6667\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.6667\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.6667\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.6667\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.6667\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.6667\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.6667\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.6667\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.6667\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.6667\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "auc_roc: 0.5\n",
      "auc_pr: 0.6666666666666666\n",
      "f1_score: 0.5333333333333333\n",
      "mcc: 0.0\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[0.00397587 0.9960242 ]\n",
      " [0.03551739 0.96448267]\n",
      " [0.03118542 0.9688146 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 11, 1141, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 11, 1141, 64  576         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 11, 1141, 64  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 11, 1141, 64  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                )                                 'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 11, 1141, 64  0           ['add_6[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_13[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 11, 1141, 64  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_14[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 11, 1141, 64  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                )                                 'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 11, 1141, 64  0           ['add_7[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 11, 1141, 1)  65          ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 12551)        0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          1255200     ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 32)           3232        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            66          ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,659\n",
      "Trainable params: 1,358,147\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 2s 332ms/step - loss: 3.0672 - accuracy: 0.5333 - val_loss: 2.6397 - val_accuracy: 0.3333\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 210ms/step - loss: 2.3863 - accuracy: 0.7333 - val_loss: 2.1993 - val_accuracy: 0.3333\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 1.9827 - accuracy: 0.7333 - val_loss: 1.8803 - val_accuracy: 0.3333\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.6317 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.6667\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.4054 - accuracy: 1.0000 - val_loss: 1.4921 - val_accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.2173 - accuracy: 1.0000 - val_loss: 1.4001 - val_accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.1041 - accuracy: 0.9333 - val_loss: 1.3412 - val_accuracy: 0.6667\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.0125 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.6667\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.9508 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.9011 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.6667\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.8550 - accuracy: 1.0000 - val_loss: 1.2224 - val_accuracy: 0.6667\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.8051 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.6667\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.7683 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.6667\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.7405 - accuracy: 1.0000 - val_loss: 1.1627 - val_accuracy: 0.6667\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.7005 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.6667\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.6649 - accuracy: 1.0000 - val_loss: 1.1244 - val_accuracy: 0.6667\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 1.1076 - val_accuracy: 0.6667\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.6113 - accuracy: 1.0000 - val_loss: 1.0935 - val_accuracy: 0.6667\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.5873 - accuracy: 1.0000 - val_loss: 1.0803 - val_accuracy: 0.6667\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.5706 - accuracy: 1.0000 - val_loss: 1.0675 - val_accuracy: 0.6667\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.5517 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.6667\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.5311 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.6667\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.5181 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.6667\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.4967 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.6667\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.4846 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.6667\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4711 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.6667\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4537 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.6667\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.4423 - accuracy: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4294 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.6667\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.4178 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6667\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.4081 - accuracy: 1.0000 - val_loss: 0.9755 - val_accuracy: 0.6667\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3965 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.6667\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3834 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.6667\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3731 - accuracy: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3638 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3555 - accuracy: 1.0000 - val_loss: 0.9400 - val_accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3483 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3370 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.6667\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3296 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.6667\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3191 - accuracy: 1.0000 - val_loss: 0.9116 - val_accuracy: 0.6667\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.6667\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.8990 - val_accuracy: 0.6667\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 195ms/step - loss: 0.2987 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.6667\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2910 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.6667\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2835 - accuracy: 1.0000 - val_loss: 0.8790 - val_accuracy: 0.6667\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2775 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.6667\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2720 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.6667\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.6667\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 0.8505 - val_accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2480 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.6667\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2410 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.6667\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.6667\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2314 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.6667\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.6667\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.8173 - val_accuracy: 0.6667\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.6667\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.6667\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1996 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.6667\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.6667\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1913 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.6667\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1872 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.6667\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1844 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.6667\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.6667\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1761 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.6667\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.6667\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.6667\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.6667\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.6667\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 0.7674 - val_accuracy: 0.6667\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.6667\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1550 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.6667\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.6667\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.6667\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.6667\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.6667\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.6667\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.6667\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.6667\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.6667\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1334 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.6667\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.6667\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.6667\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.6667\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.6667\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.6667\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.6667\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.6667\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1208 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.6667\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.6667\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1168 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.6667\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.6667\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.6667\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.6667\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.6667\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.6667\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.6667\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.6667\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.6667\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.6667\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.6667\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.6667\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.6667\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.6667\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.6667\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.6667\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.6667\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.6667\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.6667\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.6667\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.6667\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.6667\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 194ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.6667\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.6667\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.6667\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.6667\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.6667\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.6667\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.6667\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.6667\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.6667\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.6667\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.6667\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.6667\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.6667\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.6667\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.6667\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.6667\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.6667\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.6667\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.6667\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.6667\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6667\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.6667\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.6667\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.6667\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.6667\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.6667\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.6667\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.6667\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.6667\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.6667\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.6667\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.6667\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.6667\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.6667\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.6667\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x297c39820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "auc_roc: 1.0\n",
      "auc_pr: 1.0\n",
      "f1_score: 0.6666666666666666\n",
      "mcc: 0.5\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0.02553265 0.9744674 ]\n",
      " [0.944065   0.05593508]\n",
      " [0.05598043 0.9440196 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 11, 1141, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 11, 1141, 64  576         ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 11, 1141, 64  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2a-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 11, 1141, 64  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                )                                 'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 11, 1141, 64  0           ['add_8[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_17[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv1[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 11, 1141, 64  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 11, 1141, 64  32832       ['activation_18[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 11, 1141, 64  256        ['res2b-conv2[0][0]']            \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 11, 1141, 64  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                )                                 'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 11, 1141, 64  0           ['add_9[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 11, 1141, 1)  65          ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 12551)        0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          1255200     ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 32)           3232        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            66          ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,659\n",
      "Trainable params: 1,358,147\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_lst = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     x_train1 = x_train[i]\n",
    "#     y_train1 = y_train[i]\n",
    "#     x_test1 = x_test[i]\n",
    "#     y_test1 = y_test[i]\n",
    "\n",
    "#     model = ResNet(height = x_train1.shape[1], width = x_train1.shape[2], channels = 1, classes = 2)\n",
    "#     model.init_model()\n",
    "\n",
    "#     model.train(x_train1, y_train1, x_test1, y_test1, dataset, use_weights = False)\n",
    "#     y_pred = model.predict(x_test1)\n",
    "#     auc_roc, auc_pr, f1, mcc = model.evaluate(y_test1, y_pred)\n",
    "#     data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    \n",
    "#     #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "\n",
    "#     print(y_test1)\n",
    "#     print(y_pred)\n",
    "    \n",
    "# print(model.model.summary())\n",
    "\n",
    "\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "tree_row = my_maps.shape[1]\n",
    "tree_col = my_maps.shape[2]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "fold = 0\n",
    "for train_index, test_index in skf.split(my_maps, labels):\n",
    "    train_x, test_x = my_maps[train_index,:,:], my_maps[test_index,:,:]\n",
    "    train_y, test_y = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        \n",
    "    train_x = np.log(train_x + 1)\n",
    "    test_x = np.log(test_x + 1)\n",
    "        \n",
    "    c_prob = [0] * len(np.unique(labels))\n",
    "    train_weights = []\n",
    "\n",
    "    for l in np.unique(labels):\n",
    "        a = float(len(labels))\n",
    "        b = 2.0 * float((np.sum(labels==l)))\n",
    "        c_prob[int(l)] = a/b\n",
    "\n",
    "    c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "    for l in np.argmax(train_y, 1):\n",
    "        train_weights.append(c_prob[int(l)])\n",
    "    train_weights = np.array(train_weights)\n",
    "        \n",
    "    scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "    train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "    test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "    train = [train_x, train_y]\n",
    "    test = [test_x, test_y]\n",
    "\n",
    "    x_train1 = train_x\n",
    "    y_train1 = train_y\n",
    "    x_test1 = test_x\n",
    "    y_test1 = test_y\n",
    "        \n",
    "#         y_train1 = train_y\n",
    "#         y_test1 = test_y\n",
    "        \n",
    "#         x_train1 = np.zeros(train_x.shape)\n",
    "#         x_train1[train_x != 0] = 1\n",
    "        \n",
    "#         x_test1 = np.zeros(test_x.shape)\n",
    "#         x_test1[test_x != 0] = 1\n",
    "        \n",
    "        # for i in range(len(train_x)):\n",
    "        #     for j in range(len(test_x)):\n",
    "        #         if np.array_equal(train_x[i], test_x[j]):\n",
    "        #             print('train')\n",
    "        #             print(train_x[i])\n",
    "        #             print('test')\n",
    "        #             print(test_x[j])\n",
    "        \n",
    "        \n",
    "    model = ResNet(height = train_x.shape[1], width = train_x.shape[2], channels = 1, classes = 2)\n",
    "    model.init_model()\n",
    "    model.train(train_x, train_y, test_x, y_test1, dataset, use_weights = False)\n",
    "    y_pred = model.predict(test_x)\n",
    "    auc_roc, auc_pr, f1, mcc = model.evaluate(test_y, y_pred)\n",
    "    data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "    print(test_y)\n",
    "    print(y_pred)\n",
    "    print(model.model.summary())\n",
    "    \n",
    "    fold += 1\n",
    "#run += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Accuracy Metrics and Saving Metrics\n",
    "\n",
    "Option to save results of all k folds and weights of last model into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc(roc)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc(pr)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2    3         4         5\n",
       "auc(roc)  1.0  0.750000  1.0  0.500000  1.000000\n",
       "auc(pr)   1.0  0.833333  1.0  0.666667  1.000000\n",
       "f1        1.0  0.733333  1.0  0.533333  0.666667\n",
       "mcc       1.0  0.577350  1.0  0.000000  0.500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [str(i) for i in range(1,k+1)]    \n",
    "results_df = pd.DataFrame(data_lst, columns = ['auc(roc)', 'auc(pr)', 'f1', 'mcc'])\n",
    "results_df = results_df.transpose()\n",
    "results_df.columns = col\n",
    "\n",
    "#results_df.to_csv(path + \"/results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Weights\n",
    "\n",
    "Option to save model weights of last model in k fold into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.model.save_weights(path + \"/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
