{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import abspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_network import generate_network\n",
    "from utils.prepare_data import prepare_data\n",
    "from utils.popphy_io import save_params, load_params\n",
    "from utils.popphy_io import get_stat, get_stat_dict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from models.PopPhy import PopPhyCNN\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "#from models.PopPhy2 import ResNet\n",
    "from models.PopPhy2 import ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Reading Configuration\n",
    "Configuring which data to read in, minimun threshold needed in an OTU (individual sample must have at least set threshold relative abundance), and how many k folds for k fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'SKG-gender'\n",
    "threshold = 0\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features\n",
    "Reduce amount of OTU features by filtering out OTUs that contain no individual sample with a relative abundance greater than the set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Bacteroidaceae|g__Bacteroides|s__Bacteroides_acidifaciens</th>\n",
       "      <td>0.515464</td>\n",
       "      <td>6.118415</td>\n",
       "      <td>2.770585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.597435</td>\n",
       "      <td>4.111809</td>\n",
       "      <td>7.151454</td>\n",
       "      <td>2.182638</td>\n",
       "      <td>8.290361</td>\n",
       "      <td>12.971185</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560158</td>\n",
       "      <td>1.123329</td>\n",
       "      <td>6.644094</td>\n",
       "      <td>3.491985</td>\n",
       "      <td>3.254792</td>\n",
       "      <td>3.368070</td>\n",
       "      <td>12.787513</td>\n",
       "      <td>7.915906</td>\n",
       "      <td>1.973158</td>\n",
       "      <td>1.963207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.226549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.924920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_murinus</th>\n",
       "      <td>4.329897</td>\n",
       "      <td>2.217066</td>\n",
       "      <td>8.234076</td>\n",
       "      <td>3.771930</td>\n",
       "      <td>4.970400</td>\n",
       "      <td>3.011275</td>\n",
       "      <td>5.789574</td>\n",
       "      <td>4.183847</td>\n",
       "      <td>0.238001</td>\n",
       "      <td>0.679028</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192493</td>\n",
       "      <td>2.626374</td>\n",
       "      <td>15.851847</td>\n",
       "      <td>4.063979</td>\n",
       "      <td>6.629393</td>\n",
       "      <td>10.571551</td>\n",
       "      <td>4.000174</td>\n",
       "      <td>4.873927</td>\n",
       "      <td>1.402706</td>\n",
       "      <td>20.356582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_johnsonii</th>\n",
       "      <td>0.220913</td>\n",
       "      <td>1.160093</td>\n",
       "      <td>2.382185</td>\n",
       "      <td>6.871345</td>\n",
       "      <td>1.541687</td>\n",
       "      <td>0.364594</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>0.142944</td>\n",
       "      <td>2.062674</td>\n",
       "      <td>1.314529</td>\n",
       "      <td>...</td>\n",
       "      <td>4.888679</td>\n",
       "      <td>12.281465</td>\n",
       "      <td>2.992088</td>\n",
       "      <td>2.397430</td>\n",
       "      <td>1.717252</td>\n",
       "      <td>6.145251</td>\n",
       "      <td>5.048046</td>\n",
       "      <td>16.656527</td>\n",
       "      <td>3.348307</td>\n",
       "      <td>3.282027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__Bacteroidales|f__Rikenellaceae|g__Alistipes|s__Alistipes_unclassified</th>\n",
       "      <td>0.677467</td>\n",
       "      <td>0.910888</td>\n",
       "      <td>0.310720</td>\n",
       "      <td>5.453216</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.492877</td>\n",
       "      <td>0.620764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515668</td>\n",
       "      <td>0.348220</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695575</td>\n",
       "      <td>2.048889</td>\n",
       "      <td>0.625367</td>\n",
       "      <td>0.459007</td>\n",
       "      <td>3.985623</td>\n",
       "      <td>2.086914</td>\n",
       "      <td>0.400017</td>\n",
       "      <td>0.189279</td>\n",
       "      <td>0.509824</td>\n",
       "      <td>0.303830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__Lachnospiraceae NK4A136 group|s__Lachnospiraceae NK4A136 group_unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridia UCG-014|f__unclassified|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridia UCG-014|f__unclassified|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Lachnospirales|f__Lachnospiraceae|g__unclassified|s__unclassified_unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Burkholderiales|f__Burkholderiaceae|g__Burkholderia-Caballeronia-Paraburkholderia|s__Burkholderia-Caballeronia-Paraburkholderia_unclassified</th>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          1         2   \\\n",
       "0                                                                        \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.515464  6.118415   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  4.329897  2.217066   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  0.220913  1.160093   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.677467  0.910888   \n",
       "...                                                      ...       ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.042966   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.029455  0.000000   \n",
       "\n",
       "                                                          3         4   \\\n",
       "0                                                                        \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  2.770585  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.233040  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  8.234076  3.771930   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  2.382185  6.871345   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.310720  5.453216   \n",
       "...                                                      ...       ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "\n",
       "                                                          5         6   \\\n",
       "0                                                                        \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  7.597435  4.111809   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  4.970400  3.011275   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  1.541687  0.364594   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.641342  0.492877   \n",
       "...                                                      ...       ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.185002  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "\n",
       "                                                          7         8   \\\n",
       "0                                                                        \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  7.151454  2.182638   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  5.789574  4.183847   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  0.190030  0.142944   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.620764  0.000000   \n",
       "...                                                      ...       ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000  0.000000   \n",
       "\n",
       "                                                          9          10  ...  \\\n",
       "0                                                                        ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  8.290361  12.971185  ...   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  0.238001   0.679028  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  2.062674   1.314529  ...   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.515668   0.348220  ...   \n",
       "...                                                      ...        ...  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.139288  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000  ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.000000  ...   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000  ...   \n",
       "\n",
       "                                                          54         55  \\\n",
       "0                                                                         \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  1.560158   1.123329   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  3.192493   2.626374   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  4.888679  12.281465   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  2.695575   2.048889   \n",
       "...                                                      ...        ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000   \n",
       "\n",
       "                                                           56        57  \\\n",
       "0                                                                         \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   6.644094  3.491985   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...   1.226549  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  15.851847  4.063979   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   2.992088  2.397430   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   0.625367  0.459007   \n",
       "...                                                       ...       ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000  0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000  0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...   0.000000  0.000000   \n",
       "\n",
       "                                                           58         59  \\\n",
       "0                                                                          \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   3.254792   3.368070   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  11.924920   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   6.629393  10.571551   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   1.717252   6.145251   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   3.985623   2.086914   \n",
       "...                                                       ...        ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000   0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...   0.000000   0.000000   \n",
       "\n",
       "                                                           60         61  \\\n",
       "0                                                                          \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  12.787513   7.915906   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...   0.017392   0.013520   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   4.000174   4.873927   \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...   5.048046  16.656527   \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...   0.400017   0.189279   \n",
       "...                                                       ...        ...   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...   0.000000   0.000000   \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...   0.000000   0.000000   \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...   0.000000   0.000000   \n",
       "\n",
       "                                                          62         63  \n",
       "0                                                                        \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  1.973158   1.963207  \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  1.402706  20.356582  \n",
       "k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactoba...  3.348307   3.282027  \n",
       "k__Bacteria|p__Bacteroidota|c__Bacteroidia|o__B...  0.509824   0.303830  \n",
       "...                                                      ...        ...  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.000000  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Clos...  0.000000   0.000000  \n",
       "k__Bacteria|p__Firmicutes|c__Clostridia|o__Lach...  0.000000   0.000000  \n",
       "k__Bacteria|p__Proteobacteria|c__Gammaproteobac...  0.000000   0.000000  \n",
       "\n",
       "[520 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/\" + dataset\n",
    "data = pd.read_csv(path + '/abundance.tsv', index_col=0, sep='\\t', header=None)\n",
    "to_drop = data.loc[(data < threshold).all(axis=1)]\n",
    "data = data.drop(to_drop.index)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2d Matrix Representing OTU Data\n",
    "Dai et al. PopPhy-CNN's (2019) algorithm creates Phylogenetic tree from OTUs and populates tree based on OTU abundances. This tree graph structure is then converted to a 2d Matrix by taking each parent node in the tree graph and pushing them all to the left and childrens' nodes in the same order from left to right the parents were ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 63)\n",
      "There are 520 raw features...\n",
      "Building tree structure...\n",
      "Tree file not found...\n",
      "Constructing tree..\n",
      "Pruning Tree...\n",
      "Populating trees...\n",
      "There are 275 tree features...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.357206</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.498821</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.100648</td>\n",
       "      <td>0.031830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224727</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.465959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>0.031830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224727</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.014884  0.357206  0.046124  0.001916  0.078691  0.498821  0.002358   \n",
       "3  0.014884  0.100648  0.031830  0.000000  0.224727  0.046124  0.000000   \n",
       "4  0.014884  0.006189  0.094459  0.031830  0.000000  0.000000  0.000000   \n",
       "5  0.014884  0.006189  0.094459  0.000295  0.031536  0.000000  0.000000   \n",
       "6  0.014884  0.006189  0.094459  0.000295  0.031536  0.000000  0.000000   \n",
       "7  0.014884  0.000000  0.006189  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.005158  0.001474   \n",
       "\n",
       "        7         8         9    ...  447  448       449  450  451  452  453  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "1  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "2  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "3  0.001916  0.078691  0.465959  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "4  0.224727  0.046124  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "5  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "6  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "7  0.094459  0.000295  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "8  0.000000  0.000000  0.000000  ...  0.0  0.0  0.004568  0.0  0.0  0.0  0.0   \n",
       "9  0.000000  0.000000  0.000000  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   454  455  456  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "5  0.0  0.0  0.0  \n",
       "6  0.0  0.0  0.0  \n",
       "7  0.0  0.0  0.0  \n",
       "8  0.0  0.0  0.0  \n",
       "9  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 457 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_maps, raw_x, tree_x, raw_features, tree_features, labels, label_set, g, feature_df = prepare_data(path, data)\n",
    "\n",
    "pd.DataFrame(my_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets\n",
    "Splitting data into k training and k test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "input = my_maps\n",
    "target = tf.keras.utils.to_categorical(labels, 2, dtype='int64')\n",
    "    \n",
    "\n",
    "#shuffle dataset\n",
    "seed = np.random.randint(100)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(input)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(target)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "#create k training and k test sets\n",
    "groups_input = []\n",
    "groups_target = []\n",
    "k_size = len(input)//k\n",
    "start, end = 0, k_size\n",
    "for i in range(k):\n",
    "    if i == k-1:\n",
    "        group_input = input[start:]\n",
    "        group_target = target[start:]\n",
    "    else:\n",
    "        group_input = input[start:end]\n",
    "        group_target = target[start:end]\n",
    "    start += k_size\n",
    "    end += k_size\n",
    "    groups_input.append(group_input)\n",
    "    groups_target.append(group_target)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(k-1, -1, -1):\n",
    "    x_train.append(np.concatenate((groups_input[i-1], groups_input[i-2], groups_input[i-3], groups_input[i-4])))\n",
    "    y_train.append(np.concatenate((groups_target[i-1], groups_target[i-2], groups_target[i-3], groups_target[i-4])))\n",
    "\n",
    "    x_test.append(groups_input[i])\n",
    "    y_test.append(groups_target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### Training model\n",
    "Uses ConvNet that employs skipped residual identity blocks borrowed from the classic ResNet model to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 3s 569ms/step - loss: 3.4287 - accuracy: 0.5200 - val_loss: 2.5758 - val_accuracy: 0.3077\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 3.2077 - accuracy: 0.5800 - val_loss: 2.5054 - val_accuracy: 0.3077\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.2418 - accuracy: 0.7800 - val_loss: 2.4301 - val_accuracy: 0.3077\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.8938 - accuracy: 0.9600 - val_loss: 2.4087 - val_accuracy: 0.3077\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.8159 - accuracy: 0.9600 - val_loss: 2.3708 - val_accuracy: 0.3077\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.7038 - accuracy: 0.9600 - val_loss: 2.3371 - val_accuracy: 0.3077\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.7961 - accuracy: 0.9000 - val_loss: 2.2272 - val_accuracy: 0.3077\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 2.1212 - val_accuracy: 0.3077\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.4966 - accuracy: 0.9600 - val_loss: 2.0226 - val_accuracy: 0.3846\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.4038 - accuracy: 0.9600 - val_loss: 1.9531 - val_accuracy: 0.6923\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.2890 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.5385\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.2433 - accuracy: 1.0000 - val_loss: 1.8463 - val_accuracy: 0.6923\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.2211 - accuracy: 1.0000 - val_loss: 1.7918 - val_accuracy: 0.6923\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 1.1307 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.6923\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 1.0798 - accuracy: 1.0000 - val_loss: 1.6926 - val_accuracy: 0.6923\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 1.0348 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.6923\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.9945 - accuracy: 1.0000 - val_loss: 1.6096 - val_accuracy: 0.6923\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.9569 - accuracy: 1.0000 - val_loss: 1.5734 - val_accuracy: 0.6923\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.9218 - accuracy: 1.0000 - val_loss: 1.5385 - val_accuracy: 0.6923\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.8875 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.6923\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.8556 - accuracy: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.6923\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.8267 - accuracy: 1.0000 - val_loss: 1.4480 - val_accuracy: 0.6923\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.7978 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.6923\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.7693 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.6923\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.7433 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.6923\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.7189 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.7692\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.6961 - accuracy: 1.0000 - val_loss: 1.3312 - val_accuracy: 0.7692\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.6731 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.9231\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6522 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8462\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.6318 - accuracy: 1.0000 - val_loss: 1.2760 - val_accuracy: 0.7692\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.6125 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.7692\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.5940 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.7692\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.5767 - accuracy: 1.0000 - val_loss: 1.2301 - val_accuracy: 0.6923\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.5596 - accuracy: 1.0000 - val_loss: 1.2166 - val_accuracy: 0.6154\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.5435 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.5385\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5282 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.5385\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.5132 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.5385\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.4991 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.3846\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.4854 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.3846\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4724 - accuracy: 1.0000 - val_loss: 1.1495 - val_accuracy: 0.3846\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.4598 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.3846\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.4474 - accuracy: 1.0000 - val_loss: 1.1288 - val_accuracy: 0.3846\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.4358 - accuracy: 1.0000 - val_loss: 1.1190 - val_accuracy: 0.3846\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.4246 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.3846\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.4137 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.3846\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.4032 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.3846\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3934 - accuracy: 1.0000 - val_loss: 1.0852 - val_accuracy: 0.3846\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3836 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.3846\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3739 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.3846\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 182ms/step - loss: 0.3647 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.3846\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3562 - accuracy: 1.0000 - val_loss: 1.0521 - val_accuracy: 0.3846\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3487 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.3846\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3394 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.3846\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3313 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.3846\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3237 - accuracy: 1.0000 - val_loss: 1.0271 - val_accuracy: 0.3846\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3163 - accuracy: 1.0000 - val_loss: 1.0213 - val_accuracy: 0.3846\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.3846\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3020 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.3846\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2953 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.3846\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2886 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.3846\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.3846\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2760 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.3846\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2699 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.3846\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.3846\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2584 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.3846\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.3846\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.3846\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.3846\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.3846\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2323 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.3846\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.3846\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2228 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.3846\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.3846\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.3846\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.3846\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2053 - accuracy: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.4615\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2014 - accuracy: 1.0000 - val_loss: 0.8714 - val_accuracy: 0.4615\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.5385\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 0.8561 - val_accuracy: 0.5385\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1897 - accuracy: 1.0000 - val_loss: 0.8487 - val_accuracy: 0.5385\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "auc_roc: 0.9722222222222222\n",
      "auc_pr: 0.9694444444444446\n",
      "f1_score: 0.521978021978022\n",
      "mcc: 0.36514837167011077\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "[[0.1273091  0.8726909 ]\n",
      " [0.6028391  0.39716092]\n",
      " [0.3992876  0.60071236]\n",
      " [0.25360578 0.7463942 ]\n",
      " [0.19267641 0.8073236 ]\n",
      " [0.5422083  0.4577917 ]\n",
      " [0.43023077 0.56976926]\n",
      " [0.15617248 0.8438275 ]\n",
      " [0.3180974  0.6819026 ]\n",
      " [0.44250908 0.5574909 ]\n",
      " [0.5154288  0.48457125]\n",
      " [0.34404635 0.65595365]\n",
      " [0.31130177 0.6886983 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 457, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 457, 64)  576         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 10, 457, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 10, 457, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 10, 457, 64)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 10, 457, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 10, 457, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 10, 457, 64)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 457, 1)   65          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4570)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          457100      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,463\n",
      "Trainable params: 556,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 250ms/step - loss: 3.4194 - accuracy: 0.7200 - val_loss: 2.5460 - val_accuracy: 0.3846\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 2.4697 - accuracy: 0.7600 - val_loss: 2.4366 - val_accuracy: 0.5385\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 2.1970 - accuracy: 0.8600 - val_loss: 2.4398 - val_accuracy: 0.3846\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.9168 - accuracy: 0.9400 - val_loss: 2.3693 - val_accuracy: 0.3846\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.6398 - accuracy: 0.9800 - val_loss: 2.2792 - val_accuracy: 0.3846\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.5278 - accuracy: 0.9800 - val_loss: 2.2070 - val_accuracy: 0.3846\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.4163 - accuracy: 1.0000 - val_loss: 2.1377 - val_accuracy: 0.3846\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.3224 - accuracy: 1.0000 - val_loss: 2.0486 - val_accuracy: 0.3846\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 1.2404 - accuracy: 1.0000 - val_loss: 1.9733 - val_accuracy: 0.3846\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.1608 - accuracy: 1.0000 - val_loss: 1.9062 - val_accuracy: 0.3846\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.0876 - accuracy: 1.0000 - val_loss: 1.8473 - val_accuracy: 0.3846\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0191 - accuracy: 1.0000 - val_loss: 1.7907 - val_accuracy: 0.3846\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.9551 - accuracy: 1.0000 - val_loss: 1.7379 - val_accuracy: 0.3846\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.8957 - accuracy: 1.0000 - val_loss: 1.6767 - val_accuracy: 0.3846\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.8405 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.3846\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.7898 - accuracy: 1.0000 - val_loss: 1.5387 - val_accuracy: 0.3846\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.7432 - accuracy: 1.0000 - val_loss: 1.4845 - val_accuracy: 0.3846\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.7012 - accuracy: 1.0000 - val_loss: 1.4567 - val_accuracy: 0.3846\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.6591 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.3846\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.6221 - accuracy: 1.0000 - val_loss: 1.3977 - val_accuracy: 0.3846\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5878 - accuracy: 1.0000 - val_loss: 1.3663 - val_accuracy: 0.3846\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.5564 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.3846\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.5269 - accuracy: 1.0000 - val_loss: 1.2957 - val_accuracy: 0.3846\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.4995 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.3846\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.4739 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 0.3846\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4503 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.3846\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.4284 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.3846\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.4078 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.3846\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3885 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.3846\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3707 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.3846\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3541 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.3846\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3385 - accuracy: 1.0000 - val_loss: 1.0341 - val_accuracy: 0.3846\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3238 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.3846\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.3846\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2970 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.3846\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.3846\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.3846\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2628 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.3846\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2527 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.3846\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.4615\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2338 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.4615\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2252 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.4615\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.8625 - val_accuracy: 0.4615\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.8512 - val_accuracy: 0.5385\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2018 - accuracy: 1.0000 - val_loss: 0.8400 - val_accuracy: 0.5385\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1951 - accuracy: 1.0000 - val_loss: 0.8309 - val_accuracy: 0.5385\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.5385\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1818 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.6154\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1760 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.6923\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1699 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.7692\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 0.7838 - val_accuracy: 0.7692\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1593 - accuracy: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.7692\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.7692\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.7692\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.7692\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.7692\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.7342 - val_accuracy: 0.7692\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1317 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.7692\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1279 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.7692\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.7692\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1208 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.7692\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7692\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.7692\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.7692\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.7692\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.7692\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.7692\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.7692\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.7692\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 0.7692\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.7692\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.7692\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.7692\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.7692\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.7692\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.7692\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.7692\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.7692\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.9231\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9231\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "auc_roc: 0.9750000000000001\n",
      "auc_pr: 0.9763888888888889\n",
      "f1_score: 0.924009324009324\n",
      "mcc: 0.8539125638299666\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0.7077497  0.29225028]\n",
      " [0.33349457 0.66650546]\n",
      " [0.14430575 0.8556943 ]\n",
      " [0.3749211  0.6250789 ]\n",
      " [0.67161506 0.32838497]\n",
      " [0.5122556  0.4877445 ]\n",
      " [0.7210722  0.27892777]\n",
      " [0.16965108 0.8303489 ]\n",
      " [0.49639088 0.5036091 ]\n",
      " [0.2993818  0.7006182 ]\n",
      " [0.7287151  0.2712849 ]\n",
      " [0.52819324 0.47180676]\n",
      " [0.8247728  0.1752272 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 457, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 457, 64)  576         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 10, 457, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 10, 457, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 10, 457, 64)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 10, 457, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 10, 457, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 10, 457, 64)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 457, 1)   65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4570)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          457100      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,463\n",
      "Trainable params: 556,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 2s 443ms/step - loss: 3.4567 - accuracy: 0.6200 - val_loss: 2.5580 - val_accuracy: 0.3846\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 2.9186 - accuracy: 0.5800 - val_loss: 2.5679 - val_accuracy: 0.3846\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.0199 - accuracy: 0.9600 - val_loss: 2.5821 - val_accuracy: 0.3846\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 1.8290 - accuracy: 0.9800 - val_loss: 2.6179 - val_accuracy: 0.3846\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.7036 - accuracy: 0.9600 - val_loss: 2.7002 - val_accuracy: 0.3846\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.5935 - accuracy: 1.0000 - val_loss: 2.8218 - val_accuracy: 0.3846\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 1.6077 - accuracy: 0.9400 - val_loss: 2.5969 - val_accuracy: 0.3846\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.4550 - accuracy: 1.0000 - val_loss: 2.3443 - val_accuracy: 0.3846\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.3830 - accuracy: 1.0000 - val_loss: 2.1523 - val_accuracy: 0.3846\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.3024 - accuracy: 1.0000 - val_loss: 2.0087 - val_accuracy: 0.3846\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.2326 - accuracy: 1.0000 - val_loss: 1.8974 - val_accuracy: 0.4615\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.1732 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.7692\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.1191 - accuracy: 1.0000 - val_loss: 1.7362 - val_accuracy: 0.5385\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0674 - accuracy: 1.0000 - val_loss: 1.6766 - val_accuracy: 0.5385\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.0167 - accuracy: 1.0000 - val_loss: 1.6264 - val_accuracy: 0.6154\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.9691 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.6154\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.9252 - accuracy: 1.0000 - val_loss: 1.5422 - val_accuracy: 0.6154\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.8850 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.6154\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.8467 - accuracy: 1.0000 - val_loss: 1.4686 - val_accuracy: 0.6154\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.8100 - accuracy: 1.0000 - val_loss: 1.4346 - val_accuracy: 0.6154\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.7755 - accuracy: 1.0000 - val_loss: 1.4020 - val_accuracy: 0.6154\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.7438 - accuracy: 1.0000 - val_loss: 1.3713 - val_accuracy: 0.6154\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.7142 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.6154\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.6854 - accuracy: 1.0000 - val_loss: 1.3149 - val_accuracy: 0.6154\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.6595 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.6154\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.6337 - accuracy: 1.0000 - val_loss: 1.2623 - val_accuracy: 0.6154\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.6101 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.6154\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.5876 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.6154\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.5670 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.6154\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5467 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.6154\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.5279 - accuracy: 1.0000 - val_loss: 1.1551 - val_accuracy: 0.6154\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.5099 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.6154\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.4928 - accuracy: 1.0000 - val_loss: 1.1209 - val_accuracy: 0.6923\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.4768 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.6923\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.4615 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.7692\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4469 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.7692\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4329 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.8462\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.4196 - accuracy: 1.0000 - val_loss: 1.0539 - val_accuracy: 0.9231\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.4072 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.7692\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3949 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.7692\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3834 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.6923\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.6154\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3619 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.6154\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3517 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6154\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.6154\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.9812 - val_accuracy: 0.5385\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3240 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3152 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.5385\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3068 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.5385\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2990 - accuracy: 1.0000 - val_loss: 0.9531 - val_accuracy: 0.5385\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2912 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.5385\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.5385\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.9302 - val_accuracy: 0.5385\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2698 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.5385\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2638 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.5385\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2575 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.5385\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.4615\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.4615\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.2389 - accuracy: 1.0000 - val_loss: 0.8925 - val_accuracy: 0.4615\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2333 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.4615\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2283 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.4615\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.5385\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.5385\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.5385\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.5385\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2034 - accuracy: 1.0000 - val_loss: 0.8449 - val_accuracy: 0.5385\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1989 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.5385\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1947 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.5385\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1904 - accuracy: 1.0000 - val_loss: 0.8209 - val_accuracy: 0.5385\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.5385\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1827 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.5385\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.6154\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.6154\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1715 - accuracy: 1.0000 - val_loss: 0.7894 - val_accuracy: 0.6154\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.7841 - val_accuracy: 0.6154\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.6923\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1610 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.6923\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.6923\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.6923\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1516 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.6923\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "auc_roc: 0.875\n",
      "auc_pr: 0.9033978174603174\n",
      "f1_score: 0.6959706959706959\n",
      "mcc: 0.4147575310031266\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0.40270802 0.597292  ]\n",
      " [0.44983685 0.5501632 ]\n",
      " [0.86810106 0.131899  ]\n",
      " [0.52886426 0.4711357 ]\n",
      " [0.2700194  0.7299806 ]\n",
      " [0.43560398 0.564396  ]\n",
      " [0.67048204 0.32951793]\n",
      " [0.54019207 0.45980796]\n",
      " [0.19934341 0.8006566 ]\n",
      " [0.6063025  0.39369756]\n",
      " [0.5763316  0.42366844]\n",
      " [0.29306874 0.70693123]\n",
      " [0.3978432  0.60215676]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 10, 457, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 457, 64)  576         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10, 457, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 10, 457, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10, 457, 64)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 10, 457, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 10, 457, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 10, 457, 64)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 457, 1)   65          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4570)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          457100      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,463\n",
      "Trainable params: 556,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 3.5009 - accuracy: 0.5490 - val_loss: 2.5648 - val_accuracy: 0.3333\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 3.0432 - accuracy: 0.6275 - val_loss: 2.4446 - val_accuracy: 0.8333\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 2.1581 - accuracy: 0.9020 - val_loss: 2.3472 - val_accuracy: 0.6667\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.9777 - accuracy: 0.8824 - val_loss: 2.2936 - val_accuracy: 0.6667\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.7661 - accuracy: 0.9804 - val_loss: 2.2538 - val_accuracy: 0.6667\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.6542 - accuracy: 0.9804 - val_loss: 2.2518 - val_accuracy: 0.6667\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.6249 - accuracy: 0.9804 - val_loss: 2.2357 - val_accuracy: 0.6667\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.4556 - accuracy: 1.0000 - val_loss: 2.2270 - val_accuracy: 0.6667\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.4043 - accuracy: 1.0000 - val_loss: 2.2075 - val_accuracy: 0.6667\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.3229 - accuracy: 1.0000 - val_loss: 2.1750 - val_accuracy: 0.6667\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.2505 - accuracy: 1.0000 - val_loss: 2.1163 - val_accuracy: 0.6667\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.1920 - accuracy: 1.0000 - val_loss: 2.0531 - val_accuracy: 0.6667\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.1308 - accuracy: 1.0000 - val_loss: 1.9905 - val_accuracy: 0.6667\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.0755 - accuracy: 1.0000 - val_loss: 1.9329 - val_accuracy: 0.6667\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0225 - accuracy: 1.0000 - val_loss: 1.8720 - val_accuracy: 0.6667\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.9732 - accuracy: 1.0000 - val_loss: 1.8100 - val_accuracy: 0.6667\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.9280 - accuracy: 1.0000 - val_loss: 1.7480 - val_accuracy: 0.6667\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.8838 - accuracy: 1.0000 - val_loss: 1.6893 - val_accuracy: 0.6667\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.8435 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.6667\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.8061 - accuracy: 1.0000 - val_loss: 1.5733 - val_accuracy: 0.6667\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.7683 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.6667\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.7348 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.6667\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.7044 - accuracy: 1.0000 - val_loss: 1.4256 - val_accuracy: 0.6667\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.6741 - accuracy: 1.0000 - val_loss: 1.3814 - val_accuracy: 0.6667\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.6455 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.6667\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.6188 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.6667\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.5943 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.6667\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5709 - accuracy: 1.0000 - val_loss: 1.2321 - val_accuracy: 0.6667\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.5488 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.6667\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.5282 - accuracy: 1.0000 - val_loss: 1.1740 - val_accuracy: 0.6667\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.5092 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.6667\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4901 - accuracy: 1.0000 - val_loss: 1.1253 - val_accuracy: 0.6667\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.4728 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.6667\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.4562 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.6667\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.4405 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.6667\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.4260 - accuracy: 1.0000 - val_loss: 1.0479 - val_accuracy: 0.6667\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.4116 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.6667\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3981 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.7500\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3859 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.8333\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3736 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.8333\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3617 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.8333\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3507 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.8333\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3402 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.8333\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3303 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.7500\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3204 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.7500\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3114 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.8333\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3024 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.8333\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2941 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.8333\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2861 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.8333\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2784 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.8333\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 0.8856 - val_accuracy: 0.8333\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2638 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.8333\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.8702 - val_accuracy: 0.8333\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2505 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.8333\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.8333\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.8333\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2314 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.8333\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2259 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8333\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.8333\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8333\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.8333\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2050 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.8333\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2003 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.8333\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1961 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.8333\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1909 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.8333\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1866 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.8333\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.9167\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1781 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.9167\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.9167\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1702 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.9167\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.9167\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.9167\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.9167\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.9167\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1528 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.9167\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1494 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.9167\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.9167\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.9167\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.9167\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "auc_roc: 0.96875\n",
      "auc_pr: 0.9680555555555556\n",
      "f1_score: 0.9131652661064426\n",
      "mcc: 0.816496580927726\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0.74146086 0.25853914]\n",
      " [0.588635   0.41136494]\n",
      " [0.4423872  0.5576128 ]\n",
      " [0.3086274  0.69137263]\n",
      " [0.6064783  0.39352176]\n",
      " [0.7686519  0.2313481 ]\n",
      " [0.7305718  0.2694282 ]\n",
      " [0.7178592  0.2821408 ]\n",
      " [0.21027543 0.78972465]\n",
      " [0.56250286 0.43749714]\n",
      " [0.6015169  0.3984831 ]\n",
      " [0.6674384  0.3325616 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 457, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 457, 64)  576         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 10, 457, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 10, 457, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 10, 457, 64)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 10, 457, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 10, 457, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 10, 457, 64)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 457, 1)   65          ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4570)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          457100      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,463\n",
      "Trainable params: 556,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 2s 309ms/step - loss: 3.4531 - accuracy: 0.6275 - val_loss: 2.5351 - val_accuracy: 0.4167\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 2.1299 - accuracy: 0.9020 - val_loss: 2.3772 - val_accuracy: 0.7500\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 2.0417 - accuracy: 0.8627 - val_loss: 2.3113 - val_accuracy: 0.7500\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.8137 - accuracy: 0.9412 - val_loss: 2.2148 - val_accuracy: 0.6667\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.5863 - accuracy: 1.0000 - val_loss: 2.1134 - val_accuracy: 0.6667\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.4858 - accuracy: 1.0000 - val_loss: 2.0169 - val_accuracy: 0.6667\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.4042 - accuracy: 1.0000 - val_loss: 1.9517 - val_accuracy: 0.5833\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.3042 - accuracy: 1.0000 - val_loss: 1.9175 - val_accuracy: 0.5000\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.2224 - accuracy: 1.0000 - val_loss: 1.9013 - val_accuracy: 0.5000\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 1.1420 - accuracy: 1.0000 - val_loss: 1.8885 - val_accuracy: 0.4167\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0685 - accuracy: 1.0000 - val_loss: 1.8688 - val_accuracy: 0.4167\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0023 - accuracy: 1.0000 - val_loss: 1.8501 - val_accuracy: 0.4167\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.9399 - accuracy: 1.0000 - val_loss: 1.8178 - val_accuracy: 0.4167\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.8818 - accuracy: 1.0000 - val_loss: 1.7811 - val_accuracy: 0.4167\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.8293 - accuracy: 1.0000 - val_loss: 1.7434 - val_accuracy: 0.4167\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.7809 - accuracy: 1.0000 - val_loss: 1.7108 - val_accuracy: 0.4167\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.7367 - accuracy: 1.0000 - val_loss: 1.6851 - val_accuracy: 0.4167\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.6961 - accuracy: 1.0000 - val_loss: 1.6834 - val_accuracy: 0.3333\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6586 - accuracy: 1.0000 - val_loss: 1.6841 - val_accuracy: 0.3333\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.6238 - accuracy: 1.0000 - val_loss: 1.6758 - val_accuracy: 0.3333\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5919 - accuracy: 1.0000 - val_loss: 1.6663 - val_accuracy: 0.3333\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.5628 - accuracy: 1.0000 - val_loss: 1.6553 - val_accuracy: 0.3333\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.5353 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.3333\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5102 - accuracy: 1.0000 - val_loss: 1.6529 - val_accuracy: 0.3333\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.4865 - accuracy: 1.0000 - val_loss: 1.6554 - val_accuracy: 0.3333\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.4647 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.3333\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.4443 - accuracy: 1.0000 - val_loss: 1.6299 - val_accuracy: 0.3333\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.4254 - accuracy: 1.0000 - val_loss: 1.6117 - val_accuracy: 0.3333\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4073 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.3333\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.3906 - accuracy: 1.0000 - val_loss: 1.5516 - val_accuracy: 0.3333\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3749 - accuracy: 1.0000 - val_loss: 1.5206 - val_accuracy: 0.3333\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3602 - accuracy: 1.0000 - val_loss: 1.4905 - val_accuracy: 0.3333\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3463 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.3333\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.3331 - accuracy: 1.0000 - val_loss: 1.4535 - val_accuracy: 0.3333\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 1.4475 - val_accuracy: 0.3333\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3089 - accuracy: 1.0000 - val_loss: 1.4377 - val_accuracy: 0.3333\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 1.4374 - val_accuracy: 0.3333\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2875 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.3333\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2773 - accuracy: 1.0000 - val_loss: 1.4349 - val_accuracy: 0.3333\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2680 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.3333\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2589 - accuracy: 1.0000 - val_loss: 1.4329 - val_accuracy: 0.3333\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2505 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.3333\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 1.4757 - val_accuracy: 0.3333\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2344 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.3333\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2271 - accuracy: 1.0000 - val_loss: 1.4298 - val_accuracy: 0.3333\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.3901 - val_accuracy: 0.3333\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.3465 - val_accuracy: 0.3333\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.3333\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2003 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.3333\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1943 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.3333\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1886 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.3333\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.3333\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 1.2116 - val_accuracy: 0.3333\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1729 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.3333\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 1.1812 - val_accuracy: 0.3333\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 1.1408 - val_accuracy: 0.3333\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.3333\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.3333\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 1.0625 - val_accuracy: 0.3333\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.3333\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1423 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.3333\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1384 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.3333\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1349 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.4167\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.4167\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.3333\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.4167\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1216 - accuracy: 1.0000 - val_loss: 0.9805 - val_accuracy: 0.4167\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.5000\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.5000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1128 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.5000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.9109 - val_accuracy: 0.5000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.5000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.9440 - val_accuracy: 0.5000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.4167\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.4167\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.5000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.9184 - val_accuracy: 0.5000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.5000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.8710 - val_accuracy: 0.5000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.8448 - val_accuracy: 0.5833\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2990688b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "auc_roc: 0.90625\n",
      "auc_pr: 0.9227430555555556\n",
      "f1_score: 0.5687645687645687\n",
      "mcc: 0.408248290463863\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0.69392323 0.3060768 ]\n",
      " [0.07819911 0.921801  ]\n",
      " [0.13543765 0.86456233]\n",
      " [0.14367142 0.8563286 ]\n",
      " [0.13541959 0.86458045]\n",
      " [0.22656034 0.7734397 ]\n",
      " [0.5136521  0.4863479 ]\n",
      " [0.05073332 0.9492667 ]\n",
      " [0.12585357 0.8741464 ]\n",
      " [0.67757714 0.3224229 ]\n",
      " [0.05467366 0.9453264 ]\n",
      " [0.06223284 0.9377672 ]]\n",
      "Model: \"res\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10, 457, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " res2a-conv1 (Conv2D)           (None, 10, 457, 64)  576         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " res2a-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 10, 457, 64)  0           ['res2a-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2a-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " res2a-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2a-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 10, 457, 64)  0           ['res2a-batchnorm2[0][0]',       \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 10, 457, 64)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b-conv1 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm1 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv1[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 10, 457, 64)  0           ['res2b-batchnorm1[0][0]']       \n",
      "                                                                                                  \n",
      " res2b-conv2 (Conv2D)           (None, 10, 457, 64)  32832       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " res2b-batchnorm2 (BatchNormali  (None, 10, 457, 64)  256        ['res2b-conv2[0][0]']            \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 10, 457, 64)  0           ['res2b-batchnorm2[0][0]',       \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 10, 457, 64)  0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 10, 457, 1)   65          ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 4570)         0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 100)          457100      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 100)          0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 2)            202         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,463\n",
      "Trainable params: 556,951\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_lst = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     x_train1 = x_train[i]\n",
    "#     y_train1 = y_train[i]\n",
    "#     x_test1 = x_test[i]\n",
    "#     y_test1 = y_test[i]\n",
    "\n",
    "#     model = ResNet(height = x_train1.shape[1], width = x_train1.shape[2], channels = 1, classes = 2)\n",
    "#     model.init_model()\n",
    "\n",
    "#     model.train(x_train1, y_train1, x_test1, y_test1, dataset, use_weights = False)\n",
    "#     y_pred = model.predict(x_test1)\n",
    "#     auc_roc, auc_pr, f1, mcc = model.evaluate(y_test1, y_pred)\n",
    "#     data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    \n",
    "#     #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "\n",
    "#     print(y_test1)\n",
    "#     print(y_pred)\n",
    "    \n",
    "# print(model.model.summary())\n",
    "\n",
    "\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "tree_row = my_maps.shape[1]\n",
    "tree_col = my_maps.shape[2]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "fold = 0\n",
    "for train_index, test_index in skf.split(my_maps, labels):\n",
    "    train_x, test_x = my_maps[train_index,:,:], my_maps[test_index,:,:]\n",
    "    train_y, test_y = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        \n",
    "    train_x = np.log(train_x + 1)\n",
    "    test_x = np.log(test_x + 1)\n",
    "        \n",
    "    c_prob = [0] * len(np.unique(labels))\n",
    "    train_weights = []\n",
    "\n",
    "    for l in np.unique(labels):\n",
    "        a = float(len(labels))\n",
    "        b = 2.0 * float((np.sum(labels==l)))\n",
    "        c_prob[int(l)] = a/b\n",
    "\n",
    "    c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "    for l in np.argmax(train_y, 1):\n",
    "        train_weights.append(c_prob[int(l)])\n",
    "    train_weights = np.array(train_weights)\n",
    "        \n",
    "    scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "    train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "    test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "    train = [train_x, train_y]\n",
    "    test = [test_x, test_y]\n",
    "\n",
    "    #popphy_model = PopPhyCNN((tree_row, tree_col), num_class, config)\n",
    "\n",
    "    x_train1 = train_x\n",
    "    y_train1 = train_y\n",
    "    x_test1 = test_x\n",
    "    y_test1 = test_y\n",
    "        \n",
    "#         y_train1 = train_y\n",
    "#         y_test1 = test_y\n",
    "        \n",
    "#         x_train1 = np.zeros(train_x.shape)\n",
    "#         x_train1[train_x != 0] = 1\n",
    "        \n",
    "#         x_test1 = np.zeros(test_x.shape)\n",
    "#         x_test1[test_x != 0] = 1\n",
    "        \n",
    "        # for i in range(len(train_x)):\n",
    "        #     for j in range(len(test_x)):\n",
    "        #         if np.array_equal(train_x[i], test_x[j]):\n",
    "        #             print('train')\n",
    "        #             print(train_x[i])\n",
    "        #             print('test')\n",
    "        #             print(test_x[j])\n",
    "        \n",
    "        \n",
    "    model = ResNet(height = x_train1.shape[1], width = x_train1.shape[2], channels = 1, classes = 2)\n",
    "    model.init_model()\n",
    "    model.train(x_train1, y_train1, x_test1, y_test1, dataset, use_weights = False)\n",
    "    y_pred = model.predict(x_test1)\n",
    "    auc_roc, auc_pr, f1, mcc = model.evaluate(y_test1, y_pred)\n",
    "    data_lst.append([auc_roc, auc_pr, f1, mcc])\n",
    "    #model.model.save_weights(path + \"/model_weights.h5\")\n",
    "    print(y_test1)\n",
    "    print(y_pred)\n",
    "    print(model.model.summary())\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Accuracy Metrics and Saving Metrics\n",
    "\n",
    "Option to save results of all k folds and weights of last model into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc(roc)</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc(pr)</th>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.903398</td>\n",
       "      <td>0.968056</td>\n",
       "      <td>0.922743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.924009</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.913165</td>\n",
       "      <td>0.568765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.853913</td>\n",
       "      <td>0.414758</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3         4         5\n",
       "auc(roc)  0.972222  0.975000  0.875000  0.968750  0.906250\n",
       "auc(pr)   0.969444  0.976389  0.903398  0.968056  0.922743\n",
       "f1        0.521978  0.924009  0.695971  0.913165  0.568765\n",
       "mcc       0.365148  0.853913  0.414758  0.816497  0.408248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [str(i) for i in range(1,k+1)]    \n",
    "results_df = pd.DataFrame(data_lst, columns = ['auc(roc)', 'auc(pr)', 'f1', 'mcc'])\n",
    "results_df = results_df.transpose()\n",
    "results_df.columns = col\n",
    "\n",
    "#results_df.to_csv(path + \"/results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Weights\n",
    "\n",
    "Option to save model weights of last model in k fold into same directy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.model.save_weights(path + \"/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
