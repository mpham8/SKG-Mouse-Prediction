{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f7ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "#import tensorflow_datasets as tfds\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994076b",
   "metadata": {},
   "source": [
    " ## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4de94e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data, info = tfds.load(\"mnist\", with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2826d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data = data['train']\n",
    "#ds = train_data.take(5)\n",
    "data = pd.read_csv('../../data/UCr/abundance.tsv', index_col=0, sep='\\t', header=None)\n",
    "to_drop = data.loc[(data < 0.1).all(axis=1)]\n",
    "data = data.drop(to_drop.index)\n",
    "labels = np.genfromtxt('../../data/UCr/labels.txt', dtype=np.str_, delimiter=',')\n",
    "\n",
    "data_array = np.array(data).T\n",
    "\n",
    "class_0 = data_array[labels.astype(int) == 0]\n",
    "class_1 = data_array[labels.astype(int) == 1]\n",
    "\n",
    "train_data = class_0\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac163dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for example in train_data:\n",
    "#     print(list(example.keys()))\n",
    "#     image = example[\"image\"]\n",
    "#     label = example[\"label\"]\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     print(image.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34792c",
   "metadata": {},
   "source": [
    "# Training Using Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987616c3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86248ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dense_1 = tf.keras.layers.Dense(300, activation=tf.nn.relu)\n",
    "        self.dense_2 = tf.keras.layers.Dense(300, activation=tf.nn.relu)\n",
    "        self.dense_3 = tf.keras.layers.Dense(300, activation=tf.nn.relu)\n",
    "        self.dense_4 = tf.keras.layers.Dense(22, activation=tf.nn.relu)\n",
    "        #self.reshape = tf.keras.layers.Reshape((28, 28, 1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.dense_4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense_1 = tf.keras.layers.Dense(300, activation=tf.nn.leaky_relu )\n",
    "        self.dense_2 = tf.keras.layers.Dense(300, activation=tf.nn.leaky_relu )\n",
    "        self.dense_3 = tf.keras.layers.Dense(300, activation=tf.nn.leaky_relu)\n",
    "        self.dense_4 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return self.dense_4(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c698dfd",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b3303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss object: Binary Crossentropy Loss\n",
    "# real_output: Image from Data\n",
    "# fae_output: Image from Generator\n",
    "def discriminator_loss(loss_object, real_output, fake_output):\n",
    "    real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# loss object: Binary Crossentropy Loss\n",
    "# discriminator_probability: Result from Discriminator 0 = Fake 1 = Real\n",
    "def generator_loss(loss_object, discriminator_probability):\n",
    "    return loss_object(tf.ones_like(discriminator_probability), discriminator_probability)\n",
    "\n",
    "# Normalize Image between [-1,1]\n",
    "def normalize(x):\n",
    "    #image = tf.cast(x['image'], tf.float32)\n",
    "    #image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "# Save Image sample from Generator\n",
    "def save_imgs(epoch, generator, noise):\n",
    "    gen_imgs = generator(noise)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(gen_imgs.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(gen_imgs[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    fig.savefig(\"images/mnist_%d.png\" % epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a79771",
   "metadata": {},
   "source": [
    "### Callback: They allow us to save image during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d5bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim, saving_rate):\n",
    "        super(Training_Callback, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.saving_rate = saving_rate\n",
    "        \n",
    "    # Save Image sample from Generator\n",
    "#     def save_imgs(self, epoch):\n",
    "#         # Number of images = 16\n",
    "#         seed = tf.random.normal([16, self.latent_dim])\n",
    "#         gen_imgs = self.model.generator(seed)\n",
    "        \n",
    "#         fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "#         for i in range(gen_imgs.shape[0]):\n",
    "#             plt.subplot(4, 4, i + 1)\n",
    "#             plt.imshow(gen_imgs[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "#             plt.axis('off')\n",
    "\n",
    "#         fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    \n",
    "    # Called after each epoch\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         # Save image after 50 epochs\n",
    "#         if epoch % 50 == 0:\n",
    "#             self.save_imgs(epoch)\n",
    "            \n",
    "#         if epoch > 0 and epoch % self.saving_rate == 0:\n",
    "#             save_dir = \"./models/model_epoch_\" + str(epoch)\n",
    "#             if not os.path.exists(save_dir):\n",
    "#                 os.makedirs(save_dir)\n",
    "#             self.model.discriminator.save_weights(save_dir + '/discriminator_%d' % epoch)\n",
    "#             self.model.generator.save_weights(save_dir + '/generator_%d' % epoch)\n",
    "            \n",
    "#         self.best_weights = self.model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe05a5",
   "metadata": {},
   "source": [
    "## Modify train_step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c46d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    # define the models\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    # Define the compiler\n",
    "    def compile(self, disc_optimizer, gen_optimizer, loss_fn, generator_loss, discriminator_loss):\n",
    "        super(GAN, self).compile()\n",
    "        self.disc_optimizer = disc_optimizer\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.generator_loss = generator_loss\n",
    "        self.discriminator_loss = discriminator_loss\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        \n",
    "    # @tf.function: The below function is completely Tensor Code\n",
    "    # Good for optimization\n",
    "    @tf.function\n",
    "    # Modify Train step for GAN\n",
    "    def train_step(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "\n",
    "        # Define the loss function\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            generated_images = self.generator(noise)\n",
    "            real_output = self.discriminator(images)\n",
    "            fake_output = self.discriminator(generated_images)\n",
    "            \n",
    "            gen_loss = self.generator_loss(self.loss_fn, fake_output)\n",
    "            disc_loss = self.discriminator_loss(self.loss_fn, real_output, fake_output)\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_disc = tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        grad_gen = tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "\n",
    "        # Optimization Step: Update Weights & Learning Rate\n",
    "        self.disc_optimizer.apply_gradients(zip(grad_disc, self.discriminator.trainable_variables))\n",
    "        self.gen_optimizer.apply_gradients(zip(grad_gen, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"Gen Loss \": gen_loss,\"Disc Loss\" : disc_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f85591",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531b9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "epochs = 2000\n",
    "# Reduce Batch Size if GPU memory overflow\n",
    "# Better Use Google Colab\n",
    "batch_size = 2000\n",
    "# Save model after every\n",
    "saving_rate = 100\n",
    "\n",
    "# Random Seed for Shuffling Data\n",
    "buffer_size = 5000\n",
    "\n",
    "# defining optimizer for Models\n",
    "gen_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "# Shuffle & Batch Data\n",
    "#train_dataset = train_data.map(normalize).shuffle(buffer_size , reshuffle_each_iteration=True).batch(batch_size)\n",
    "train_dataset = train_data\n",
    "\n",
    "# Define Loss Function\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c8ff7",
   "metadata": {},
   "source": [
    "### Create GAN & Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b2b0b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 02:03:40.518619: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-10 02:03:40.518734: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "disc = Discriminator()\n",
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b00fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator=disc, generator=gen, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    disc_optimizer=disc_optimizer,\n",
    "    gen_optimizer=gen_optimizer,\n",
    "    loss_fn=cross_entropy,\n",
    "    generator_loss = generator_loss,\n",
    "    discriminator_loss = discriminator_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ee3a7",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a784c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 02:03:40.680619: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/ipykernel_43786/3184849390.py\", line 31, in train_step  *\n        fake_output = self.discriminator(generated_images)\n    File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/__autograph_generated_fileb3u1l539.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).dense_2, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"discriminator\" \"                 f\"(type Discriminator).\n    \n    in user code:\n    \n        File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/ipykernel_43786/2267820864.py\", line 32, in call  *\n            x = self.dense_2(x)\n        File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 22, but received input with shape (None, 512)\n    \n    \n    Call arguments received by layer \"discriminator\" \"                 f\"(type Discriminator):\n      • inputs=tf.Tensor(shape=(None, 512), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m training_callback \u001b[38;5;241m=\u001b[39m Training_Callback(\u001b[38;5;241m10\u001b[39m, saving_rate)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtraining_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/__autograph_generated_file89vmqzlj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/__autograph_generated_filewnh0nxy4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     13\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerator, (ag__\u001b[38;5;241m.\u001b[39mld(noise),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m real_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdiscriminator, (ag__\u001b[38;5;241m.\u001b[39mld(images),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 15\u001b[0m fake_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdiscriminator, (ag__\u001b[38;5;241m.\u001b[39mld(generated_images),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerator_loss, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_fn, ag__\u001b[38;5;241m.\u001b[39mld(fake_output)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     17\u001b[0m disc_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdiscriminator_loss, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_fn, ag__\u001b[38;5;241m.\u001b[39mld(real_output), ag__\u001b[38;5;241m.\u001b[39mld(fake_output)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/__autograph_generated_fileb3u1l539.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdense_2, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdense_3, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/ipykernel_43786/3184849390.py\", line 31, in train_step  *\n        fake_output = self.discriminator(generated_images)\n    File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/__autograph_generated_fileb3u1l539.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).dense_2, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"discriminator\" \"                 f\"(type Discriminator).\n    \n    in user code:\n    \n        File \"/var/folders/vq/qfqzj01x6ms_n2n90qm33bvr0000gn/T/ipykernel_43786/2267820864.py\", line 32, in call  *\n            x = self.dense_2(x)\n        File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Users/michael/miniconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 22, but received input with shape (None, 512)\n    \n    \n    Call arguments received by layer \"discriminator\" \"                 f\"(type Discriminator):\n      • inputs=tf.Tensor(shape=(None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_callback = Training_Callback(10, saving_rate)\n",
    "gan.fit(\n",
    "    train_dataset, \n",
    "    epochs=epochs,\n",
    "    callbacks=[training_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9de7f9",
   "metadata": {},
   "source": [
    "## Save Best Gen & Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e5baea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_callback.model.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc626cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.save_weights('./models/discriminator')\n",
    "gen.save_weights('./models/generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7587e8f",
   "metadata": {},
   "source": [
    "## Load Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9325cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "disc1 = Discriminator()\n",
    "gen1 = Generator()\n",
    "disc1.load_weights('./models/discriminator')\n",
    "gen1.load_weights('./models/generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b58edc9-a5c5-4149-9273-39e09cf90557",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([100, latent_dim])\n",
    "generated_images = gen1.predict(noise)\n",
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4c0870-7567-4a72-82dd-b76a528c717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generated_images.T\n",
    "generated_df = pd.DataFrame(generated)\n",
    "#generated_df = generated_df.where(generated_df > 0, 0)\n",
    "generated_df = generated_df.div(generated_df.sum(axis=0), axis=1)\n",
    "generated_df\n",
    "\n",
    "#generated.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6166216e-ea1f-4feb-9fd2-49a5bcadccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated.sum(axis = 0)\n",
    "#len(generated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e687b-e299-4d98-a1e3-bf1ff1019ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c535cfe4-94ca-4eb3-9776-8347a439e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_df.to_csv('0.csv', sep=',', index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3687ba-e630-4adf-acb7-33bb63e0791e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
